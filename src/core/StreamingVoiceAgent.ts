/**
 * StreamingVoiceAgent - Orquestrador de voz com streaming
 * 
 * Respons√°vel por:
 * - Pipeline de streaming: LLM gera texto ‚Üí TTS gera √°udio ‚Üí reproduz imediatamente
 * - Menor lat√™ncia poss√≠vel (Time to First Audio)
 * - Suporte a barge-in (interrup√ß√£o)
 * - M√©tricas de lat√™ncia detalhadas
 */

import { EventEmitter } from 'events';
import {
  VoiceAgentConfig,
  CallSession,
  ConversationTurn,
  TurnMetrics,
  FillerContext,
  CallSummary,
  LatencyBreakdown,
  ITranscriber,
  ILLM,
  ITTS,
  IFillerManager,
  IMetricsCollector,
  TranscriptionResult,
  STTTimingMetrics,
} from '../types';
import { Logger } from '../utils/Logger';
import { LocalAudioProvider } from '../providers/LocalAudioProvider';
import { ContextualFillerManager } from './ContextualFillerManager';
import { LatencyAnalyzer } from '../utils/LatencyAnalyzer';
import { CallRecorder } from '../utils/CallRecorder';
import { AudioRoom } from '../utils/AudioRoom';
import { config as appConfig } from '../config';
import { VoiceIntelligence } from './VoiceIntelligence';
import { TurnStateManager } from './TurnStateManager';
import { EchoFilter } from './EchoFilter';
import { AcknowledgmentManager } from './AcknowledgmentManager';

// Configura√ß√µes de streaming
const STREAMING_CONFIG = {
  MIN_CHARS_FOR_TTS: 80,          // M√≠nimo de caracteres antes de enviar para TTS (aumentado)
  SENTENCE_DELIMITERS: ['.', '!', '?', ':', ';', ','], // Delimitadores de frase
  MAX_BUFFER_CHARS: 250,          // M√°ximo de caracteres no buffer antes de for√ßar flush (aumentado)
};

interface StreamingVoiceAgentConfig {
  transcriber: ITranscriber;
  llm: ILLM;
  tts: ITTS;
  fillerManager?: IFillerManager;
  metrics?: IMetricsCollector;
  systemPrompt: string;
  localProvider: LocalAudioProvider;
}

interface StreamingMetrics {
  turnId: string;
  sttStart: number;
  sttEnd: number;
  llmStart: number;
  llmFirstToken: number;
  ttsStart: number;
  ttsFirstChunk: number;
  playbackStart: number;
  playbackEnd: number;
  totalTokens: number;
  interrupted: boolean;
  // M√©tricas detalhadas do STT (separadas de speechDuration e vadDelay)
  sttTimingMetrics?: STTTimingMetrics;
}

export class StreamingVoiceAgent extends EventEmitter {
  private config: StreamingVoiceAgentConfig;
  private logger: Logger;
  private activeSessions: Map<string, CallSession> = new Map();
  private currentMetrics: StreamingMetrics | null = null;
  private isProcessing: boolean = false;
  private isGreetingInProgress: boolean = false; // Bloqueia processamento durante sauda√ß√£o
  private greetingTranscription: string = ''; // Buffer para transcri√ß√µes durante sauda√ß√£o (combinadas com pr√≥xima fala)
  private useStreamingSTT: boolean = false; // Usa STT em streaming (Scribe)
  private contextualFillerManager: ContextualFillerManager | null = null; // Fillers contextualizados (desabilitados por enquanto)
  private wasInterrupted: boolean = false; // Flag para indicar que houve barge-in
  private bargeInTimestamp: number = 0; // Timestamp do √∫ltimo barge-in
  private static readonly BARGE_IN_GRACE_PERIOD_MS = 800; // Ignorar transcri√ß√µes por 800ms ap√≥s barge-in
  private pendingTranscriptionCallId: string | null = null; // CallId da transcri√ß√£o que est√° sendo processada
  
  // Pr√©-processamento com transcri√ß√µes parciais
  private lastPartialText: string = '';
  private lastPartialTime: number = 0;
  private prebuiltLLMContext: Array<{ role: 'system' | 'user' | 'assistant'; content: string }> | null = null;
  private partialSentenceComplete: boolean = false; // Indica se detectamos fim de frase na parcial

  // Sistema de cancelamento e reprocessamento
  // Quando usu√°rio volta a falar durante processamento (antes do √°udio), cancela e reprocessa
  private shouldCancelProcessing: boolean = false; // Flag para cancelar processamento atual
  private pendingTranscriptionText: string = ''; // Transcri√ß√£o que estava sendo processada
  private continuationDetected: boolean = false; // Usu√°rio continuou falando
  private hasStartedPlayback: boolean = false; // Flag para saber se j√° enviamos √°udio (mais preciso que isCurrentlyPlaying)
  
  // üÜï Transcri√ß√£o parcial durante reprodu√ß√£o (para usar ap√≥s barge-in)
  private partialDuringPlayback: string = ''; // Guarda transcri√ß√£o parcial enquanto agente fala
  private lastPartialDuringPlaybackTime: number = 0; // Timestamp da √∫ltima parcial durante playback
  
  // üÜï Anti-eco: guardar √∫ltima resposta do agente para filtrar
  private lastAgentResponse: string = ''; // √öltima resposta do agente
  private lastCancelLogTime: number = 0; // Para debounce de logs de cancelamento
  private static readonly CANCEL_LOG_DEBOUNCE_MS = 500; // M√≠nimo entre logs de cancelamento

  // Grava√ß√£o de chamadas
  private callRecorder: CallRecorder | null = null;
  private audioRoom: AudioRoom | null = null;

  // Camada de intelig√™ncia centralizada (pensamentos, contexto, extra√ß√£o de nome)
  private intelligence: VoiceIntelligence;
  
  // M√≥dulos de gerenciamento de estado (compartilhados com VoiceAgent)
  private turnState: TurnStateManager;
  private echoFilter: EchoFilter;
  private acknowledgmentManager: AcknowledgmentManager;

  constructor(config: StreamingVoiceAgentConfig) {
    super();
    this.config = config;
    this.logger = new Logger('StreamingAgent');
    
    // Detectar se o transcriber suporta streaming
    this.useStreamingSTT = !!(
      this.config.transcriber.startStream &&
      this.config.transcriber.feedAudio &&
      this.config.transcriber.onTranscript
    );
    
    if (this.useStreamingSTT) {
      this.logger.info('üöÄ Modo STT: Streaming (ElevenLabs Scribe)');
      
      // Inicializar gerador de fillers contextualizados
      this.contextualFillerManager = new ContextualFillerManager({
        llm: this.config.llm,
        tts: this.config.tts,
        useQuickLLM: false, // Usar templates (mais r√°pido). Mude para true para LLM
      });
      this.logger.info('üéØ Fillers contextualizados habilitados');
    } else {
      this.logger.info('üì¶ Modo STT: Batch (OpenAI Whisper)');
    }

    // Inicializar camada de intelig√™ncia centralizada
    this.intelligence = new VoiceIntelligence({
      llm: this.config.llm,
      systemPrompt: this.config.systemPrompt,
      enableThinking: appConfig.thinkingEngine?.enabled ?? false,
    });
    
    // Inicializar m√≥dulos de gerenciamento de estado
    this.turnState = new TurnStateManager();
    this.echoFilter = new EchoFilter();
    this.acknowledgmentManager = new AcknowledgmentManager(this.config.tts);
  }

  /**
   * Inicia uma sess√£o de conversa local
   */
  async startLocalSession(prospectData?: { name?: string; company?: string }): Promise<string> {
    const callId = await this.config.localProvider.makeCall('+5511999999999');
    
    const session: CallSession = {
      id: callId,
      phoneNumber: 'local',
      prospectName: prospectData?.name || undefined, // N√£o definir nome inicialmente - ser√° coletado
      companyName: prospectData?.company || undefined,
      startedAt: new Date(),
      status: 'active',
      conversationHistory: [],
      metrics: {
        totalDuration: 0,
        turns: [],
        averageLatency: { stt: 0, llm: 0, tts: 0, total: 0, timeToFirstAudio: 0 },
        peakLatency: { stt: 0, llm: 0, tts: 0, total: 0, timeToFirstAudio: 0 },
        fillersUsed: 0,
        transcriptionErrors: 0,
      },
      internalThoughts: [], // Inicializar array de pensamentos internos
    };

    this.activeSessions.set(callId, session);
    
    // Configurar m√≥dulos de estado para modo single-session
    this.turnState.setSingleSession(callId);
    this.echoFilter.setSingleSession(callId);
    this.acknowledgmentManager.setSingleSession(callId);
    
    // Inicializar gravador de chamadas (para transcri√ß√µes)
    this.callRecorder = new CallRecorder(callId);
    this.callRecorder.start();
    
    // Inicializar AudioRoom (para grava√ß√£o de √°udio mixada)
    const recordingPath = this.callRecorder.getRecordingFolder();
    if (recordingPath) {
      this.audioRoom = new AudioRoom();
      this.audioRoom.start(`${recordingPath}/call_recording.wav`);
    }
    
    // Configurar modo de VAD baseado no tipo de STT
    if (this.useStreamingSTT) {
      // MODO STREAMING (Scribe): VAD externo, chunks enviados diretamente
      this.config.localProvider.setVADMode('external');
      
      // Iniciar stream do transcriber com retry em caso de erro
      try {
        await this.config.transcriber.startStream!(callId);
      } catch (error) {
        this.logger.error('‚ùå Erro ao iniciar Scribe, tentando reconectar...', error);
        // Tentar reconectar ap√≥s 1 segundo
        await new Promise(resolve => setTimeout(resolve, 1000));
        try {
          await this.config.transcriber.startStream!(callId);
          this.logger.info('‚úÖ Reconectado ao Scribe ap√≥s erro');
        } catch (retryError) {
          this.logger.error('‚ùå Falha ao reconectar Scribe:', retryError);
          throw retryError;
        }
      }
      
      // Callback para chunks de √°udio - envia diretamente para o Scribe
      // NOTA: Durante a sauda√ß√£o, o LocalAudioProvider s√≥ envia chunks que n√£o s√£o eco
      // Isso permite capturar a fala do usu√°rio (ex: "Al√¥?") para combinar com pr√≥xima fala
      this.config.localProvider.onAudioChunk(callId, (chunk: Buffer) => {
        // Gravar √°udio do usu√°rio no AudioRoom
        if (this.audioRoom) {
          this.audioRoom.feedUserAudio(chunk);
        }
        
        // Verificar se Scribe ainda est√° conectado antes de enviar
        if (this.config.transcriber.feedAudio) {
          // Verificar conex√£o antes de enviar (se m√©todo dispon√≠vel)
          const scribe = this.config.transcriber as any;
          if (scribe.isStreamConnected && !scribe.isStreamConnected()) {
            this.logger.warn('‚ö†Ô∏è Scribe desconectado, tentando reconectar...');
            // Tentar reconectar em background (n√£o bloquear)
            this.config.transcriber.startStream!(callId).catch(err => {
              this.logger.error('Erro ao reconectar Scribe:', err);
            });
            return;
          }
          this.config.transcriber.feedAudio(callId, chunk);
        } else {
          this.logger.warn('‚ö†Ô∏è Scribe feedAudio n√£o dispon√≠vel - chunks n√£o ser√£o enviados');
        }
      });
      
      // Callback para transcri√ß√µes finais do Scribe
      // L√ìGICA DA MAIN: Simples e direta
      this.config.transcriber.onTranscript!(callId, async (result) => {
        const resultText = result.text.trim();
        
        // PRIMEIRO: Verificar se √© eco do agente (ignorar completamente)
        if (this.echoFilter.isLikelyAgentEcho(resultText)) {
          this.logger.info(`üîá Ignorando eco do agente na transcri√ß√£o final: "${resultText}"`);
          // Resetar flags de cancelamento se estavam setadas
          if (this.shouldCancelProcessing) {
            this.shouldCancelProcessing = false;
            this.continuationDetected = false;
          }
          return; // N√£o processar eco
        }
        
        // Verificar se transcri√ß√£o parece corrompida (eco do agente, onomatopeias)
        const isLikelyCorrupted = this.echoFilter.isTranscriptionCorrupted(resultText);
        
        // Se temos transcri√ß√£o parcial capturada durante playback e resultado parece corrompido
        if (this.partialDuringPlayback && isLikelyCorrupted) {
          this.logger.warn(`‚ö†Ô∏è Transcri√ß√£o final parece corrompida: "${resultText}"`);
          this.logger.info(`üîÑ Usando transcri√ß√£o parcial capturada: "${this.partialDuringPlayback.substring(0, 50)}..."`);
          
          // Usar a transcri√ß√£o parcial em vez da corrompida
          const fixedResult: TranscriptionResult = {
            ...result,
            text: this.partialDuringPlayback,
          };
          
          // Resetar
          this.partialDuringPlayback = '';
          this.continuationDetected = false;
          this.pendingTranscriptionText = '';
          
          if (!this.isGreetingInProgress) {
            await this.processTranscription(callId, fixedResult);
          }
          return;
        }
        
        // Se detectamos continua√ß√£o, esta √© a transcri√ß√£o completa - juntar com anterior
        if (this.continuationDetected && this.pendingTranscriptionText) {
          const combinedText = `${this.pendingTranscriptionText} ${result.text}`.trim();
          this.logger.info(`üîó Transcri√ß√µes combinadas: "${combinedText.substring(0, 50)}..."`);
          
          // Criar novo resultado com texto combinado
          const combinedResult: TranscriptionResult = {
            ...result,
            text: combinedText,
          };
          
          // Resetar flags
          this.continuationDetected = false;
          this.pendingTranscriptionText = '';
          this.shouldCancelProcessing = false;
          this.partialDuringPlayback = '';
          
          // Processar transcri√ß√£o combinada
          await this.processTranscription(callId, combinedResult);
          return;
        }
        
        // Resetar transcri√ß√£o parcial (n√£o usada)
        this.partialDuringPlayback = '';
        
        // Durante a sauda√ß√£o: guardar transcri√ß√£o para combinar com pr√≥xima fala
        // O "Al√¥?" do usu√°rio √© resposta natural, n√£o deve causar barge-in
        if (this.isGreetingInProgress) {
          const existingText = this.greetingTranscription;
          this.greetingTranscription = existingText ? `${existingText} ${resultText}` : resultText;
          this.logger.info(`üëã Transcri√ß√£o durante sauda√ß√£o guardada: "${resultText}" - ser√° combinada com pr√≥xima fala`);
          return;
        }
        
        // Combinar com transcri√ß√£o guardada durante sauda√ß√£o (se houver)
        let textToProcess = resultText;
        if (this.greetingTranscription) {
          textToProcess = `${this.greetingTranscription} ${resultText}`.trim();
          this.greetingTranscription = '';
          this.logger.info(`üîó Transcri√ß√£o combinada com sauda√ß√£o: "${textToProcess.substring(0, 50)}..."`);
        }
        
        if (!this.isProcessing) {
          this.logger.debug(`üìù Recebida transcri√ß√£o do Scribe: "${textToProcess}"`);
          const processResult: TranscriptionResult = { ...result, text: textToProcess };
          await this.processTranscription(callId, processResult);
        } else {
          // Estamos processando, mas n√£o detectamos continua√ß√£o via parciais
          // Pode acontecer se a fala foi muito r√°pida - marcar para reprocessar
          this.logger.debug(`‚ö†Ô∏è Nova transcri√ß√£o durante processamento: "${textToProcess.substring(0, 30)}..."`);
          if (!this.config.localProvider.isCurrentlyPlaying()) {
            // Ainda n√£o come√ßou √°udio - marcar para cancelar e reprocessar
            this.shouldCancelProcessing = true;
            this.continuationDetected = true;
            // A pr√≥xima transcri√ß√£o vai combinar
          }
        }
      });
      
      // Listener para erros do Scribe (se EventEmitter)
      const scribe = this.config.transcriber as any;
      if (scribe.on && typeof scribe.on === 'function') {
        scribe.on('error', (error: Error) => {
          this.logger.error('‚ùå Erro do Scribe:', error);
          // Tentar reconectar automaticamente
          if (!this.isGreetingInProgress) {
            this.logger.info('üîÑ Tentando reconectar Scribe...');
            this.config.transcriber.startStream!(callId).catch(err => {
              this.logger.error('Erro ao reconectar Scribe:', err);
            });
          }
        });
      }
      
      // Callback para transcri√ß√µes parciais - com pr√©-processamento para menor lat√™ncia
      if (this.config.transcriber.onPartialTranscript) {
        this.config.transcriber.onPartialTranscript(callId, (text) => {
          this.emit('partial:transcript', callId, text);
          
          const trimmedText = text.trim();
          
          // Filtrar eco do agente (res√≠duos que podem vazar mesmo com filtro no LocalAudioProvider)
          if (this.echoFilter.isLikelyAgentEcho(trimmedText)) {
            this.logger.debug(`üîá Ignorando eco do agente: "${trimmedText.substring(0, 30)}..."`);
            return; // N√£o processar eco
          }
          
          // Filtrar transcri√ß√µes muito curtas ou onomatopeias
          const isNoise = /^(h+[um]+|hum+|uhum+|ah+|eh+|oh+|uh+)[.!?,\s]*$/i.test(trimmedText) 
                         || trimmedText.length < 5;
          if (isNoise) {
            this.logger.debug(`üîá Ignorando ru√≠do/onomatopeia: "${trimmedText}"`);
            return;
          }
          
          // DURANTE SAUDA√á√ÉO: Guardar transcri√ß√£o parcial para usar depois
          // N√£o processamos, mas guardamos para o handler de playback:interrupted
          if (this.isGreetingInProgress && this.config.localProvider.isCurrentlyPlaying() && trimmedText.length > 5) {
            const isLikelyEcho = /^(oi[,.\s]*)+$/i.test(trimmedText);
            if (!isLikelyEcho && trimmedText.length > this.partialDuringPlayback.length) {
              this.partialDuringPlayback = trimmedText;
              this.logger.info(`üëÇ Transcri√ß√£o parcial durante sauda√ß√£o: "${trimmedText.substring(0, 40)}..." (ser√° combinada)`);
            }
          }
          
          // DETEC√á√ÉO DE CONTINUA√á√ÉO: Se estamos processando E usu√°rio volta a falar
          // Cancela processamento atual para reprocessar com transcri√ß√£o completa
          if (this.isProcessing && !this.isGreetingInProgress && trimmedText.length > 5) {
            
            if (!this.hasStartedPlayback) {
              // CASO 1: √Åudio ainda n√£o come√ßou - cancela silenciosamente e reprocessa
              if (!this.shouldCancelProcessing) {
                this.logger.info(`üîÑ Usu√°rio continuou falando: "${trimmedText.substring(0, 30)}..." - cancelando processamento`);
                this.shouldCancelProcessing = true;
                this.continuationDetected = true;
                this.pendingTranscriptionText = trimmedText; // Guardar para combinar depois
                
                // üéµ Tocar onomatopeia de escuta ativa ("Uhum", "Hm", "Ok")
                this.playListeningAcknowledgment(callId).catch(err => {
                  this.logger.debug('Erro ao tocar acknowledgment (n√£o cr√≠tico):', err);
                });
              }
            } else {
              // CASO 2: √Åudio j√° come√ßou - guardar transcri√ß√£o parcial e fazer barge-in
              // Essa transcri√ß√£o pode vir do buffer flushed ap√≥s barge-in via VAD de energia,
              // ou de √°udio que passou pelo EchoCanceller como n√£o-eco
              const isLikelyEcho = /^(oi[,.\s]*)+$/i.test(trimmedText);
              
              if (!isLikelyEcho && trimmedText.length > this.partialDuringPlayback.length) {
                this.partialDuringPlayback = trimmedText;
                this.lastPartialDuringPlaybackTime = Date.now();
                this.logger.info(`üëÇ Transcri√ß√£o parcial durante playback: "${trimmedText.substring(0, 40)}..."`);
                
                // üîá Disparar barge-in via c√≥digo (backup do VAD de energia)
                if (!this.wasInterrupted) {
                  this.logger.info('üîá Barge-in via transcri√ß√£o parcial - usu√°rio est√° falando!');
                  this.config.localProvider.stopPlayback();
                  // Nota: o evento playback:interrupted ser√° emitido pelo LocalAudioProvider
                }
              }
            }
          }
          
          // üÜï CASO 3: Barge-in durante reprodu√ß√£o (quando isProcessing j√° √© false)
          // Isso acontece quando o LLM/TTS terminou mas o √°udio ainda est√° sendo reproduzido
          // A main tinha isso como parte do CASO 2, mas s√≥ funciona se isProcessing = true
          if (!this.isProcessing && !this.isGreetingInProgress && 
              this.config.localProvider.isCurrentlyPlaying() && trimmedText.length > 5) {
            const isLikelyEcho = /^(oi[,.\s]*)+$/i.test(trimmedText);
            
            if (!isLikelyEcho && !this.wasInterrupted) {
              this.partialDuringPlayback = trimmedText;
              this.logger.info(`üëÇ Transcri√ß√£o parcial durante playback (p√≥s-processamento): "${trimmedText.substring(0, 40)}..."`);
              this.logger.info('üîá Barge-in via transcri√ß√£o parcial - usu√°rio est√° falando!');
              this.config.localProvider.stopPlayback();
              // Nota: o evento playback:interrupted ser√° emitido pelo LocalAudioProvider
            }
          }
          
          // Pr√©-processamento: detectar poss√≠vel fim de frase e pr√©-construir contexto LLM
          if (!this.isProcessing && !this.isGreetingInProgress && 
              !this.config.localProvider.isCurrentlyPlaying() && trimmedText.length > 5) {
            this.handlePartialTranscriptForPreprocessing(callId, trimmedText);
          }
        });
      }
    } else {
      // MODO BATCH (Whisper): VAD interno, √°udio acumulado
      this.config.localProvider.setVADMode('internal');
      
      // Callback de √°udio ap√≥s VAD detectar fim da fala
      this.config.localProvider.onAudioReceived(callId, async (audio: Buffer) => {
        await this.processStreamingTurn(callId, audio);
      });
    }

    // Listener para barge-in
    this.config.localProvider.on('playback:interrupted', (interruptedCallId: string) => {
      // Durante a sauda√ß√£o: guardar transcri√ß√£o parcial para combinar depois
      // N√ÉO processamos imediatamente, mas guardamos para uso posterior
      if (this.isGreetingInProgress) {
        // Guardar transcri√ß√£o parcial (se houver) em greetingTranscription
        if (this.partialDuringPlayback) {
          const existingText = this.greetingTranscription;
          this.greetingTranscription = existingText 
            ? `${existingText} ${this.partialDuringPlayback}` 
            : this.partialDuringPlayback;
          this.logger.info(`üëã Transcri√ß√£o durante sauda√ß√£o (barge-in) guardada: "${this.partialDuringPlayback}" - ser√° combinada com pr√≥xima fala`);
          this.partialDuringPlayback = '';
        } else {
          this.logger.info(`üëã Barge-in durante sauda√ß√£o detectado - aguardando transcri√ß√£o`);
        }
        return;
      }
      
      this.wasInterrupted = true;
      this.bargeInTimestamp = Date.now();
      
      if (this.currentMetrics) {
        this.currentMetrics.interrupted = true;
      }
      
      // Se temos transcri√ß√£o parcial capturada durante playback, logar
      if (this.partialDuringPlayback) {
        this.logger.info(`üîá Barge-in detectado - transcri√ß√£o parcial capturada: "${this.partialDuringPlayback.substring(0, 50)}..."`);
        // Guardar a transcri√ß√£o parcial como "pendente" para usar quando vier a completa
        this.pendingTranscriptionText = this.partialDuringPlayback;
        this.continuationDetected = true;
      } else {
        this.logger.info('üîá Barge-in detectado - cancelando TODOS os processamentos');
      }
      
      // Interromper grava√ß√£o do agente no AudioRoom (descartar segmento atual)
      if (this.audioRoom) {
        this.audioRoom.interruptAgent();
      }
      
      // IMPORTANTE: Resetar timers de lat√™ncia do STT para m√©tricas corretas
      // Isso evita que o tempo de √°udio enviado durante fala do agente seja contado como lat√™ncia
      const scribe = this.config.transcriber as any;
      if (scribe.resetTimingOnBargeIn) {
        scribe.resetTimingOnBargeIn();
      }
      if (scribe.setAgentSpeaking) {
        scribe.setAgentSpeaking(false); // Agente parou de falar (foi interrompido)
      }
      
      // Cancelar processamento atual se estiver em andamento
      if (this.isProcessing) {
        this.logger.warn('‚ö†Ô∏è Cancelando processamento em andamento devido a barge-in');
        this.isProcessing = false;
      }
      
      // Se houver transcri√ß√£o pendente, marcar para ignorar
      if (this.pendingTranscriptionCallId) {
        this.logger.warn(`‚ö†Ô∏è Ignorando transcri√ß√£o pendente de ${this.pendingTranscriptionCallId} devido a barge-in`);
        this.pendingTranscriptionCallId = null;
      }
      
      // Resetar hasStartedPlayback (agente parou de falar)
      this.hasStartedPlayback = false;
      
      // Auto-reset do flag ap√≥s grace period
      setTimeout(() => {
        if (this.bargeInTimestamp > 0 && Date.now() - this.bargeInTimestamp >= StreamingVoiceAgent.BARGE_IN_GRACE_PERIOD_MS) {
          this.wasInterrupted = false;
          this.bargeInTimestamp = 0;
          // üÜï Resetar transcri√ß√£o parcial ap√≥s grace period
          this.partialDuringPlayback = '';
          this.logger.debug('‚úÖ Flag de barge-in auto-resetada ap√≥s grace period');
        }
      }, StreamingVoiceAgent.BARGE_IN_GRACE_PERIOD_MS + 100);
    });

    // Iniciar grava√ß√£o
    await this.config.localProvider.startRecording(callId);

    // Pr√©-carregar √°udios de acknowledgment em background (lat√™ncia zero quando precisar)
    this.acknowledgmentManager.preload().catch(err => {
      this.logger.debug('Erro ao pr√©-carregar acknowledgments (n√£o cr√≠tico):', err);
    });

    this.emit('session:started', callId);
    this.logger.info(`‚úÖ Sess√£o ${callId} iniciada - Fale algo!`);

    // Gerar sauda√ß√£o inicial
    // Durante a sauda√ß√£o: DESABILITAR barge-in mas CONTINUAR capturando √°udio
    // O "Al√¥?" do usu√°rio √© resposta natural, n√£o deve interromper a apresenta√ß√£o
    // Mas queremos capturar essa fala para combinar com a pr√≥xima
    this.isGreetingInProgress = true;
    this.config.localProvider.setBargeInEnabled(false); // Desabilita barge-in durante sauda√ß√£o
    
    await this.generateGreeting(callId);
    
    // Aguardar playback terminar naturalmente (sem interrup√ß√£o)
    await this.waitForPlaybackEnd(callId);
    
    this.config.localProvider.setBargeInEnabled(true); // Reabilita barge-in ap√≥s sauda√ß√£o
    this.isGreetingInProgress = false;
    
    // Se houve transcri√ß√£o durante sauda√ß√£o, logar
    if (this.greetingTranscription) {
      this.logger.info(`üëã Transcri√ß√£o guardada durante sauda√ß√£o: "${this.greetingTranscription}" - ser√° combinada com pr√≥xima fala`);
    }

    return callId;
  }

  /**
   * Aguarda o playback terminar ou ser interrompido
   * Usado ap√≥s a sauda√ß√£o para n√£o processar "Al√¥?" como barge-in
   */
  private waitForPlaybackEnd(callId: string): Promise<void> {
    return new Promise<void>((resolve) => {
      // Se n√£o est√° reproduzindo, resolver imediatamente
      if (!this.config.localProvider.isCurrentlyPlaying()) {
        resolve();
        return;
      }

      const MAX_WAIT_MS = 10000; // Timeout m√°ximo de 10s (seguran√ßa)
      let resolved = false;

      const cleanup = () => {
        if (!resolved) {
          resolved = true;
          this.config.localProvider.off('playback:ended', onEnded);
          this.config.localProvider.off('playback:interrupted', onInterrupted);
          resolve();
        }
      };

      const onEnded = (endedCallId: string) => {
        if (endedCallId === callId) {
          this.logger.info('‚úÖ Sauda√ß√£o finalizada naturalmente');
          cleanup();
        }
      };

      const onInterrupted = (interruptedCallId: string) => {
        if (interruptedCallId === callId) {
          this.logger.info('üëã Sauda√ß√£o interrompida pelo usu√°rio');
          cleanup();
        }
      };

      this.config.localProvider.on('playback:ended', onEnded);
      this.config.localProvider.on('playback:interrupted', onInterrupted);

      // Timeout de seguran√ßa
      setTimeout(cleanup, MAX_WAIT_MS);
    });
  }

  /**
   * Gera sauda√ß√£o inicial - Simula liga√ß√£o de vendas
   * Primeiro coleta o nome, depois se apresenta
   */
  private async generateGreeting(callId: string): Promise<void> {
    const session = this.activeSessions.get(callId);
    if (!session) return;

    this.logger.info('üìû Gerando abertura da liga√ß√£o...');

    // Usar prompt de sauda√ß√£o do config
    const greetingPrompt = appConfig.agent.greetingPrompt
      .replace('{prospectName}', session.prospectName || 'Ainda n√£o coletado - voc√™ precisa perguntar')
      .replace('{companyName}', session.companyName || 'N√£o informada');

    const greetingMessages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }> = [
      { role: 'system', content: greetingPrompt },
    ];

    // Gerar sauda√ß√£o com streaming
    await this.streamLLMToTTS(callId, greetingMessages, session);
  }

  /**
   * Toca um filler GEN√âRICO imediatamente (antes de saber o que o usu√°rio disse)
   * Usado em paralelo com STT para dar feedback instant√¢neo
   */
  private async playFillerGeneric(callId: string, session: CallSession): Promise<void> {
    if (!this.config.fillerManager) {
      return; // Fillers n√£o configurados
    }

    try {
      const conversationStage = this.intelligence.detectConversationStage(session);
      
      // Usar filler gen√©rico (n√£o sabemos ainda o que o usu√°rio disse)
      const filler = this.config.fillerManager.getFiller({
        conversationStage,
        prospectName: session.prospectName,
        // Sem lastUserMessage - for√ßa filler gen√©rico
      });

      if (filler) {
        this.logger.info(`üéµ Tocando filler: "${filler.text}"`);
        await this.config.localProvider.sendAudio(callId, filler.audioBuffer);
        session.metrics.fillersUsed++;
      }
    } catch (error) {
      // Falha no filler n√£o deve interromper o fluxo
      this.logger.warn('Erro ao tocar filler:', error);
    }
  }

  // NOTA: detectConversationStage foi movido para VoiceIntelligence
  // NOTA: isTranscriptionCorrupted e isLikelyAgentEcho foram movidos para EchoFilter

  /**
   * Pr√©-processa transcri√ß√µes parciais para reduzir lat√™ncia
   * Detecta padr√µes de fim de frase e pr√©-constr√≥i contexto do LLM
   */
  private handlePartialTranscriptForPreprocessing(callId: string, partialText: string): void {
    const now = Date.now();
    const session = this.activeSessions.get(callId);
    if (!session) return;

    // Detectar se parece fim de frase (pontua√ß√£o ou pausa)
    const trimmedText = partialText.trim();
    const endsWithPunctuation = /[.!?]$/.test(trimmedText);
    const timeSinceLastPartial = now - this.lastPartialTime;
    const hasSignificantPause = this.lastPartialTime > 0 && timeSinceLastPartial > 200;
    
    // Atualizar estado da transcri√ß√£o parcial
    this.lastPartialText = trimmedText;
    this.lastPartialTime = now;

    // Se detectamos poss√≠vel fim de frase, pr√©-construir contexto do LLM
    if ((endsWithPunctuation || hasSignificantPause) && trimmedText.length >= 10) {
      // Criar c√≥pia tempor√°ria do hist√≥rico com a transcri√ß√£o parcial
      const tempHistory = [...session.conversationHistory];
      tempHistory.push({
        role: 'user',
        content: trimmedText,
        timestamp: new Date(),
      });

      // Construir mensagens para o LLM usando hist√≥rico tempor√°rio
      const tempSession = { ...session, conversationHistory: tempHistory };
      this.prebuiltLLMContext = this.intelligence.buildLLMMessages(tempSession);
      this.partialSentenceComplete = true;
      
      this.logger.debug(`‚ö° Pr√©-processamento: contexto LLM pr√©-constru√≠do para "${trimmedText.substring(0, 30)}..."`);
    }
  }

  /**
   * Reseta estado de pr√©-processamento
   */
  private resetPreprocessingState(): void {
    this.lastPartialText = '';
    this.lastPartialTime = 0;
    this.prebuiltLLMContext = null;
    this.partialSentenceComplete = false;
  }

  /**
   * Toca uma onomatopeia curta de escuta ativa ("Uhum", "Hm", "Ok")
   * Usado quando detectamos que o usu√°rio continuou falando
   * D√° feedback de que o agente est√° ouvindo
   */
  private async playListeningAcknowledgment(callId: string): Promise<void> {
    try {
      const ack = await this.acknowledgmentManager.getAcknowledgment();
      if (!ack) {
        // Cooldown ou desabilitado
        return;
      }

      // Gravar no AudioRoom se dispon√≠vel
      if (this.audioRoom) {
        this.audioRoom.feedAgentAudio(ack.audio);
      }

      // Tocar √°udio (n√£o bloqueia - √© s√≥ um feedback r√°pido)
      await this.config.localProvider.sendAudio(callId, ack.audio);
      
      // Finalizar segmento
      if (this.audioRoom) {
        this.audioRoom.endAgentSegment();
      }
    } catch (error) {
      // Erro n√£o cr√≠tico - n√£o deve interromper o fluxo
      this.logger.debug('Erro ao tocar acknowledgment:', error);
    }
  }

  /**
   * Processa um turno de conversa com streaming completo
   */
  async processStreamingTurn(callId: string, userAudio: Buffer): Promise<void> {
    const session = this.activeSessions.get(callId);
    if (!session) {
      this.logger.error(`Sess√£o n√£o encontrada: ${callId}`);
      return;
    }

    // Ignorar √°udio durante a sauda√ß√£o inicial
    if (this.isGreetingInProgress) {
      this.logger.debug('Sauda√ß√£o em andamento, ignorando √°udio...');
      return;
    }

    // Ignorar √°udio enquanto o agente est√° falando (evita processar enquanto reproduz)
    if (this.config.localProvider.isCurrentlyPlaying()) {
      this.logger.debug('Agente ainda falando, ignorando √°udio...');
      return;
    }

    if (this.isProcessing) {
      this.logger.debug('J√° processando, ignorando...');
      return;
    }

    this.isProcessing = true;
    const turnId = `turn-${Date.now()}`;

    // Inicializar m√©tricas
    this.currentMetrics = {
      turnId,
      sttStart: Date.now(),
      sttEnd: 0,
      llmStart: 0,
      llmFirstToken: 0,
      ttsStart: 0,
      ttsFirstChunk: 0,
      playbackStart: 0,
      playbackEnd: 0,
      totalTokens: 0,
      interrupted: false,
    };

    try {
      // ============================================
      // FASE 1: Speech-to-Text
      // ============================================
      this.logger.info('üìù Transcrevendo...');
      
      const transcription = await this.config.transcriber.transcribe(userAudio);
      this.currentMetrics.sttEnd = Date.now();
      
      const sttDuration = this.currentMetrics.sttEnd - this.currentMetrics.sttStart;
      this.logger.info(`üìù STT (${sttDuration}ms): "${transcription.text}"`);

      // Validar transcri√ß√£o
      if (!transcription.text || transcription.text.trim().length < 2) {
        this.logger.warn('Transcri√ß√£o muito curta, ignorando turno');
        this.isProcessing = false;
        return;
      }

      // Adicionar ao hist√≥rico
      session.conversationHistory.push({
        role: 'user',
        content: transcription.text,
        timestamp: new Date(),
      });

      this.emit('user:spoke', callId, transcription.text);

      // ============================================
      // FASE 2: LLM Streaming ‚Üí TTS Streaming ‚Üí Play
      // ============================================
      const messages = this.intelligence.buildLLMMessages(session);
      await this.streamLLMToTTS(callId, messages, session);

      // ============================================
      // FASE 3: Calcular m√©tricas
      // ============================================
      this.currentMetrics.playbackEnd = Date.now();
      this.recordTurnMetrics(session);

    } catch (error) {
      this.logger.error(`Erro no turno ${turnId}:`, error);
      this.emit('error', error, `turn:${turnId}`);
    } finally {
      this.isProcessing = false;
    }
  }

  /**
   * Processa uma transcri√ß√£o j√° pronta (modo streaming - Scribe)
   * Pula a etapa de STT pois o Scribe j√° transcreveu via streaming
   */
  async processTranscription(callId: string, transcription: TranscriptionResult): Promise<void> {
    const session = this.activeSessions.get(callId);
    if (!session) {
      this.logger.error(`Sess√£o n√£o encontrada: ${callId}`);
      return;
    }

    // Ignorar durante sauda√ß√£o
    if (this.isGreetingInProgress) {
      return;
    }

    // Verificar se houve barge-in ANTES de qualquer processamento
    // Usar timestamp para garantir que o grace period seja respeitado
    const timeSinceBargeIn = Date.now() - this.bargeInTimestamp;
    if (this.wasInterrupted && timeSinceBargeIn < StreamingVoiceAgent.BARGE_IN_GRACE_PERIOD_MS) {
      this.logger.debug(`‚ö†Ô∏è Ignorando transcri√ß√£o devido a barge-in recente (${timeSinceBargeIn}ms atr√°s)`);
      return;
    }
    
    // Resetar flag se passou o grace period
    if (this.wasInterrupted && timeSinceBargeIn >= StreamingVoiceAgent.BARGE_IN_GRACE_PERIOD_MS) {
      this.wasInterrupted = false;
      this.bargeInTimestamp = 0;
      this.logger.debug('‚úÖ Flag de barge-in resetada (grace period expirado)');
    }

    // Ignorar enquanto agente fala (a menos que tenha sido interrompido)
    if (this.config.localProvider.isCurrentlyPlaying()) {
      this.logger.debug('Agente ainda falando, ignorando transcri√ß√£o...');
      return;
    }

    if (this.isProcessing) {
      this.logger.debug('J√° processando, ignorando...');
      return;
    }
    
    // Verifica√ß√£o adicional: se houve barge-in durante o check acima, cancelar
    if (this.wasInterrupted) {
      this.logger.debug('‚ö†Ô∏è Barge-in detectado durante verifica√ß√£o, cancelando');
      return;
    }

    // Marcar transcri√ß√£o como pendente
    this.pendingTranscriptionCallId = callId;
    this.isProcessing = true;
    this.partialDuringPlayback = ''; // Reset - novo processamento
    const turnId = `turn-${Date.now()}`;

    // M√©tricas - STT j√° aconteceu via streaming
    // Usar m√©tricas detalhadas do Scribe se dispon√≠veis
    const timingMetrics = transcription.timingMetrics;
    const sttRealLatency = timingMetrics?.realLatency || transcription.duration || 0;
    
    // IMPORTANTE: sttEnd = momento atual (quando a transcri√ß√£o final chegou)
    // Isso √© o ponto de refer√™ncia para Time to First Audio
    const now = Date.now();
    
    this.currentMetrics = {
      turnId,
      sttStart: timingMetrics?.startTime || now - sttRealLatency,
      sttEnd: now, // Momento que a transcri√ß√£o final chegou (in√≠cio do processamento LLM)
      llmStart: 0,
      llmFirstToken: 0,
      ttsStart: 0,
      ttsFirstChunk: 0,
      playbackStart: 0,
      playbackEnd: 0,
      totalTokens: 0,
      interrupted: false,
      sttTimingMetrics: timingMetrics, // Guardar m√©tricas detalhadas
    };

    const transcriptText = transcription.text.trim();
    
    // Ignorar apenas transcri√ß√µes extremamente curtas (ru√≠do)
    // Respostas de 1 palavra como "Sim", "N√£o", "Isso", "Ok" s√£o v√°lidas
    if (transcriptText.length < 2) {
      this.logger.debug(`Ignorando transcri√ß√£o muito curta: "${transcriptText}"`);
      this.isProcessing = false;
      this.pendingTranscriptionCallId = null;
      return;
    }
    
    // Log com m√©tricas separadas
    if (timingMetrics) {
      this.logger.info(`üìù STT Scribe:`);
      this.logger.info(`   ‚ö° Lat√™ncia REAL: ${timingMetrics.realLatency}ms (target: <300ms)`);
      this.logger.info(`   üó£Ô∏è Dura√ß√£o da fala: ${timingMetrics.speechDuration}ms (n√£o √© lat√™ncia)`);
      this.logger.info(`   ‚è±Ô∏è VAD wait: ${timingMetrics.vadWaitTime}ms`);
      this.logger.info(`   üìù Texto: "${transcriptText}"`);
    } else {
      this.logger.info(`üìù STT Scribe (${sttRealLatency}ms): "${transcriptText}"`);
    }

    try {
      // Verificar barge-in novamente antes de processar (pode ter acontecido durante valida√ß√£o)
      if (this.wasInterrupted) {
        this.logger.debug('‚ö†Ô∏è Barge-in detectado antes de processar, cancelando');
        this.isProcessing = false;
        this.pendingTranscriptionCallId = null;
        return;
      }

      // Verificar se deve cancelar (usu√°rio continuou falando)
      if (this.shouldCancelProcessing) {
        this.logger.info(`üîÑ Cancelando processamento - aguardando continua√ß√£o do usu√°rio`);
        this.pendingTranscriptionText = transcriptText; // Salvar para combinar depois
        this.shouldCancelProcessing = false;
        this.isProcessing = false;
        this.pendingTranscriptionCallId = null;
        return;
      }

      // Fillers gen√©ricos desabilitados - causavam pausas estranhas
      // Apenas fillers contextuais (baseados em transcri√ß√µes parciais) s√£o usados

      // Adicionar ao hist√≥rico (j√° validado acima)
      session.conversationHistory.push({
        role: 'user',
        content: transcriptText,
        timestamp: new Date(),
      });
      
      // Gravar transcri√ß√£o do usu√°rio
      if (this.callRecorder) {
        this.callRecorder.addTranscriptEntry('user', transcriptText);
      }

      // Tentar extrair nome se ainda n√£o tiver coletado (usa intelig√™ncia centralizada)
      this.intelligence.tryUpdateProspectName(session, transcriptText);

      this.emit('user:spoke', callId, transcriptText);

      // Verificar barge-in ou continua√ß√£o antes de gerar resposta
      if (this.wasInterrupted) {
        this.logger.debug('‚ö†Ô∏è Barge-in detectado antes de gerar resposta, cancelando');
        this.isProcessing = false;
        this.pendingTranscriptionCallId = null;
        this.resetPreprocessingState();
        return;
      }
      
      // üÜï Verificar se deve cancelar (usu√°rio continuou falando)
      if (this.shouldCancelProcessing) {
        this.logger.info(`üîÑ Cancelando antes de LLM - usu√°rio ainda est√° falando`);
        this.pendingTranscriptionText = transcriptText;
        this.shouldCancelProcessing = false;
        this.isProcessing = false;
        this.pendingTranscriptionCallId = null;
        this.resetPreprocessingState();
        return;
      }

      // LLM ‚Üí TTS ‚Üí Play
      // Usar contexto pr√©-constru√≠do se dispon√≠vel e texto for similar
      let messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }>;
      
      if (this.prebuiltLLMContext && this.partialSentenceComplete && 
          this.lastPartialText && transcriptText.includes(this.lastPartialText.substring(0, 20))) {
        // Usar contexto pr√©-constru√≠do (economiza tempo de constru√ß√£o)
        messages = this.prebuiltLLMContext;
        // Atualizar a √∫ltima mensagem do usu√°rio com o texto final completo
        const lastMessage = messages[messages.length - 1];
        if (lastMessage && lastMessage.role === 'user') {
          lastMessage.content = transcriptText;
        }
        this.logger.debug('‚ö° Usando contexto LLM pr√©-constru√≠do');
      } else {
        // Construir contexto normalmente (usa intelig√™ncia centralizada)
        messages = this.intelligence.buildLLMMessages(session);
      }
      
      // Resetar estado de pr√©-processamento
      this.resetPreprocessingState();
      
      await this.streamLLMToTTS(callId, messages, session);

      // M√©tricas
      this.currentMetrics.playbackEnd = Date.now();
      this.recordTurnMetrics(session);

    } catch (error) {
      this.logger.error(`Erro no turno ${turnId}:`, error);
      this.emit('error', error, `turn:${turnId}`);
    } finally {
      this.isProcessing = false;
      this.pendingTranscriptionCallId = null;
      this.resetPreprocessingState(); // Garantir reset do estado de pr√©-processamento
      
      // üÜï Resetar flags de continua√ß√£o se processamento completou com sucesso
      if (!this.shouldCancelProcessing) {
        this.pendingTranscriptionText = '';
        this.continuationDetected = false;
      }
      
      // Resetar flag de playback
      this.hasStartedPlayback = false;
      
      // Flag de barge-in √© resetada automaticamente ap√≥s o grace period (800ms)
    }
  }

  /**
   * Gera resposta do LLM e sintetiza TTS com streaming REAL
   * 
   * FLUXO OTIMIZADO (streaming chunk por chunk):
   * 1. LLM come√ßa a gerar texto (streaming)
   * 2. Assim que tiver uma frase/cl√°usula completa, envia para TTS
   * 3. TTS sintetiza e envia √°udio enquanto LLM continua gerando
   * 4. Reduz Time to First Audio significativamente
   */
  private async streamLLMToTTS(
    callId: string,
    messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }>,
    session: CallSession
  ): Promise<void> {
    if (!this.currentMetrics) {
      this.currentMetrics = {
        turnId: `greeting-${Date.now()}`,
        sttStart: Date.now(),
        sttEnd: Date.now(),
        llmStart: Date.now(),
        llmFirstToken: 0,
        ttsStart: 0,
        ttsFirstChunk: 0,
        playbackStart: 0,
        playbackEnd: 0,
        totalTokens: 0,
        interrupted: false,
      };
    }

    this.currentMetrics.llmStart = Date.now();
    
    let fullResponse = '';
    let isFirstAudio = true;
    let llmFirstTokenTime = 0;

    this.logger.info('ü§ñ Gerando resposta com streaming REAL...');
    
    // Resetar estado de interrup√ß√£o para permitir nova reprodu√ß√£o
    this.currentMetrics.interrupted = false;
    this.config.localProvider.resetInterruptState();
    
    // üÜï Resetar flag de playback - ainda n√£o enviamos √°udio
    this.hasStartedPlayback = false;
    
    // NOTA: N√ÉO chamar setAgentSpeaking(true) aqui - s√≥ quando primeiro √°udio for enviado
    // Isso permite detectar se usu√°rio continua falando durante processamento LLM
    const scribe = this.config.transcriber as any;
    
    // ===== STREAMING REAL: LLM ‚Üí TTS chunk por chunk =====
    // Delimitadores de senten√ßa/cl√°usula para dividir texto
    const SENTENCE_DELIMITERS = ['.', '!', '?'];
    const CLAUSE_DELIMITERS = [',', ';', ':'];
    // Chunks MUITO maiores para evitar buffer underflow
    // O TTS leva ~300-400ms para processar cada chunk, ent√£o precisamos de chunks grandes
    const MIN_CHARS_FOR_TTS = 80; // Aumentado: chunks maiores = menos gaps
    const MAX_BUFFER_CHARS = 250; // Aumentado: permite 2-3 frases completas
    
    let textBuffer = ''; // Buffer de texto acumulado do LLM
    let chunkIndex = 0;
    
    // Fila de chunks de texto para processar SEQUENCIALMENTE (evita buffer underflow)
    const textChunkQueue: { text: string; isLast: boolean }[] = [];
    let isProcessingQueue = false;
    
    /**
     * Encontra ponto de corte seguro (n√£o fragmenta palavras)
     * Procura √∫ltimo espa√ßo ou pontua√ß√£o antes do limite
     */
    const findSafeBreakPoint = (text: string, maxChars: number): number => {
      if (text.length <= maxChars) return text.length;
      
      // Procura √∫ltimo espa√ßo ou pontua√ß√£o antes do limite
      let breakPoint = maxChars;
      for (let i = maxChars - 1; i >= Math.min(maxChars - 30, MIN_CHARS_FOR_TTS); i--) {
        const char = text[i];
        if (char === ' ' || SENTENCE_DELIMITERS.includes(char) || CLAUSE_DELIMITERS.includes(char)) {
          breakPoint = i + 1; // Inclui o espa√ßo/pontua√ß√£o
          break;
        }
      }
      return breakPoint;
    };
    
    // Fun√ß√£o para processar a fila de chunks sequencialmente
    const processQueueSequentially = async (): Promise<void> => {
      if (isProcessingQueue) return; // J√° est√° processando
      isProcessingQueue = true;
      
      while (textChunkQueue.length > 0) {
        // üÜï Verificar cancelamento antes de processar cada chunk da fila
        if (this.shouldCancelProcessing && !this.hasStartedPlayback) {
          this.logger.debug(`üîÑ Limpando fila TTS (${textChunkQueue.length} chunks) - usu√°rio continuou falando`);
          textChunkQueue.length = 0; // Limpar fila
          break;
        }
        
        const item = textChunkQueue.shift()!;
        await processTextChunk(item.text, item.isLast);
      }
      
      isProcessingQueue = false;
    };
    
    // Fun√ß√£o para processar um chunk de texto no TTS
    const processTextChunk = async (text: string, isLast: boolean = false): Promise<void> => {
      if (!text.trim() || this.currentMetrics?.interrupted) return;
      
      // üÜï Verificar se deve cancelar antes de enviar para TTS
      if (this.shouldCancelProcessing && !this.hasStartedPlayback) {
        this.logger.debug('üîÑ Cancelando TTS - usu√°rio continuou falando');
        return;
      }
      
      const idx = chunkIndex++;
      this.logger.debug(`üìù TTS chunk ${idx}: "${text.substring(0, 30)}..."`);
      
      if (idx === 0) {
        this.currentMetrics!.ttsStart = Date.now();
      }
      
      try {
        if (!this.config.tts.synthesizeStream) {
          throw new Error('TTS n√£o suporta streaming');
        }
        
        await this.config.tts.synthesizeStream(text, async (audioChunk: Buffer) => {
          if (this.currentMetrics?.interrupted) return;

          // üÜï Verificar cancelamento ANTES de iniciar reprodu√ß√£o
          // Isso √© cr√≠tico: se usu√°rio voltou a falar durante LLM/TTS, n√£o reproduzir
          if (this.shouldCancelProcessing && !this.hasStartedPlayback) {
            this.logger.debug('üîÑ Cancelando reprodu√ß√£o - usu√°rio continuou falando');
            return; // N√£o reproduzir este chunk nem os pr√≥ximos
          }

          if (isFirstAudio) {
            this.currentMetrics!.ttsFirstChunk = Date.now();
            this.currentMetrics!.playbackStart = Date.now();
            
            const timeToFirstAudio = this.currentMetrics!.ttsFirstChunk - this.currentMetrics!.sttEnd;
            this.logger.info(`‚ö° Time to First Audio: ${timeToFirstAudio}ms (LLM: ${llmFirstTokenTime - this.currentMetrics!.llmStart}ms)`);
            isFirstAudio = false;
            
            // üÜï Marcar que j√° come√ßamos a reproduzir (n√£o pode mais cancelar)
            this.hasStartedPlayback = true;
            
            // üîä AGORA sim o agente est√° falando - notificar STT
            // Isso permite que transcri√ß√µes parciais sejam detectadas ANTES do √°udio come√ßar
            if (scribe.setAgentSpeaking) {
              scribe.setAgentSpeaking(true);
            }
          }

          // Gravar √°udio do agente no AudioRoom
          if (this.audioRoom) {
            this.audioRoom.feedAgentAudio(audioChunk);
          }

          // Enviar para buffer de streaming
          await this.config.localProvider.sendAudioStream(callId, audioChunk);
        });
      } catch (error) {
        this.logger.error(`Erro no TTS chunk ${idx}:`, error);
      }
    };
    
    // Adicionar chunk √† fila e processar
    const enqueueTextChunk = (text: string, isLast: boolean = false): void => {
      // üÜï N√£o adicionar √† fila se cancelamento foi solicitado
      if (this.shouldCancelProcessing && !this.hasStartedPlayback) {
        this.logger.debug('üîÑ Ignorando chunk TTS - cancelamento solicitado');
        return;
      }
      
      textChunkQueue.push({ text, isLast });
      // Iniciar processamento se n√£o estiver rodando
      processQueueSequentially().catch(err => {
        this.logger.error('Erro ao processar fila TTS:', err);
      });
    };
    
    // Usar LLM com streaming real
    if (this.config.llm.generateStream) {
      try {
        const response = await this.config.llm.generateStream(messages, (chunk: string) => {
          if (this.currentMetrics?.interrupted) return;
          
          // üÜï Verificar se deve cancelar (usu√°rio continuou falando)
          if (this.shouldCancelProcessing) {
            if (this.hasStartedPlayback) {
              // J√° enviamos algum √°udio, n√£o podemos cancelar mais - continuar normalmente
              return;
            } else {
              // Ainda n√£o enviamos √°udio - podemos cancelar
              // üÜï Debounce para n√£o logar v√°rias vezes
              const now = Date.now();
              if (now - this.lastCancelLogTime > StreamingVoiceAgent.CANCEL_LOG_DEBOUNCE_MS) {
                this.logger.info('üîÑ Cancelando LLM streaming - usu√°rio continuou falando');
                this.lastCancelLogTime = now;
              }
              return;
            }
          }
          
          // Marcar primeiro token
          if (llmFirstTokenTime === 0) {
            llmFirstTokenTime = Date.now();
            this.currentMetrics!.llmFirstToken = llmFirstTokenTime;
          }
          
          fullResponse += chunk;
          textBuffer += chunk;
          
          // Verificar se temos uma senten√ßa completa (prioridade) ou cl√°usula
          const trimmedBuffer = textBuffer.trim();
          const lastChar = trimmedBuffer.slice(-1);
          const hasSentenceEnd = SENTENCE_DELIMITERS.includes(lastChar);
          const hasClauseEnd = CLAUSE_DELIMITERS.includes(lastChar);
          const hasEnoughChars = trimmedBuffer.length >= MIN_CHARS_FOR_TTS;
          const bufferFull = trimmedBuffer.length >= MAX_BUFFER_CHARS;
          
          // Enviar para TTS se:
          // 1. Senten√ßa completa com chars suficientes, OU
          // 2. Buffer cheio (usar ponto de corte seguro para n√£o fragmentar palavras)
          if (hasSentenceEnd && hasEnoughChars) {
            enqueueTextChunk(trimmedBuffer);
            textBuffer = '';
          } else if (bufferFull) {
            // IMPORTANTE: Encontrar ponto de corte seguro para n√£o fragmentar palavras
            const breakPoint = findSafeBreakPoint(trimmedBuffer, MAX_BUFFER_CHARS);
            const textToSend = trimmedBuffer.substring(0, breakPoint).trim();
            const remaining = trimmedBuffer.substring(breakPoint);
            
            if (textToSend.length >= MIN_CHARS_FOR_TTS) {
              enqueueTextChunk(textToSend);
              textBuffer = remaining;
            }
          }
          // Cl√°usula s√≥ envia se buffer est√° MUITO cheio (reduz fragmenta√ß√£o)
          // Aumentado de 0.7 para 0.9 para evitar underflows
          else if (hasClauseEnd && trimmedBuffer.length >= MAX_BUFFER_CHARS * 0.9) {
            enqueueTextChunk(trimmedBuffer);
            textBuffer = '';
          }
        });
        
        // Processar texto restante no buffer
        if (textBuffer.trim()) {
          enqueueTextChunk(textBuffer.trim(), true);
        }
        
        // Aguardar fila de TTS terminar
        while (textChunkQueue.length > 0 || isProcessingQueue) {
          await new Promise(resolve => setTimeout(resolve, 50));
        }
        
        const llmDuration = llmFirstTokenTime - this.currentMetrics.llmStart;
        this.logger.info(`‚úÖ LLM Streaming (${llmDuration}ms first token): "${fullResponse.substring(0, 50)}..."`);
        
      } catch (error) {
        this.logger.warn('Erro no LLM streaming, usando fallback batch:', error);
        // Fallback para modo batch
        const response = await this.config.llm.generate(messages, { maxTokens: 80 });
        fullResponse = response.text;
        this.currentMetrics.llmFirstToken = Date.now();
        await processTextChunk(fullResponse, true);
      }
    } else {
      // Fallback: LLM n√£o suporta streaming
      const response = await this.config.llm.generate(messages, { maxTokens: 80 });
      fullResponse = response.text;
      this.currentMetrics.llmFirstToken = Date.now();
      
      const llmDuration = this.currentMetrics.llmFirstToken - this.currentMetrics.llmStart;
      this.logger.info(`‚úÖ LLM Batch (${llmDuration}ms): "${fullResponse.substring(0, 50)}..."`);
      
      await processTextChunk(fullResponse, true);
    }

    // üÜï Se foi cancelado antes de qualquer √°udio, n√£o adicionar ao hist√≥rico
    if (this.shouldCancelProcessing && !this.hasStartedPlayback) {
      this.logger.info('üîÑ Processamento cancelado antes do √°udio - aguardando continua√ß√£o');
      // Notificar STT que agente n√£o est√° mais "falando" (nunca come√ßou)
      if (scribe.setAgentSpeaking) {
        scribe.setAgentSpeaking(false);
      }
      return; // Sair sem adicionar ao hist√≥rico
    }
    
    // Finalizar streaming
    this.config.localProvider.endAudioStream();
    
    // Finalizar segmento de √°udio do agente no AudioRoom
    if (this.audioRoom) {
      this.audioRoom.endAgentSegment();
    }
    
    // Notificar STT que agente parou de falar
    if (scribe.setAgentSpeaking) {
      scribe.setAgentSpeaking(false);
    }
    
    // Adicionar resposta ao hist√≥rico
    session.conversationHistory.push({
      role: 'agent',
      content: fullResponse,
      timestamp: new Date(),
    });
    
    // Gravar transcri√ß√£o do agente
    if (this.callRecorder) {
      this.callRecorder.addTranscriptEntry('agent', fullResponse);
    }

    this.logger.info(`ü§ñ Resposta: "${fullResponse.substring(0, 80)}${fullResponse.length > 80 ? '...' : ''}"`);
    this.emit('agent:spoke', callId, fullResponse);
    
    // Guardar resposta para filtrar eco
    this.lastAgentResponse = fullResponse;
    this.echoFilter.registerAgentResponse(fullResponse);

    // Disparar processamento de pensamentos em paralelo (n√£o bloqueia)
    // Aproveita o tempo de reprodu√ß√£o do √°udio (~1-3s) enquanto o usu√°rio ouve
    // Usa intelig√™ncia centralizada para processamento de pensamentos
    if (this.intelligence.isThinkingEnabled()) {
      const userMessages = session.conversationHistory.filter(t => t.role === 'user');
      if (userMessages.length > 0) {
        this.intelligence.processThoughtsInParallel(session, fullResponse).catch(err => {
          this.logger.warn('Erro ao processar pensamentos (n√£o cr√≠tico):', err);
        });
      }
    }
  }

  /**
   * Decide se deve enviar o buffer atual para TTS
   */
  private shouldFlushToTTS(buffer: string, lastChunk: string): boolean {
    // Se buffer atingiu tamanho m√°ximo
    if (buffer.length >= STREAMING_CONFIG.MAX_BUFFER_CHARS) {
      return true;
    }

    // Se buffer tem tamanho m√≠nimo E termina com delimitador
    if (buffer.length >= STREAMING_CONFIG.MIN_CHARS_FOR_TTS) {
      const lastChar = buffer.trim().slice(-1);
      if (STREAMING_CONFIG.SENTENCE_DELIMITERS.includes(lastChar)) {
        return true;
      }
    }

    return false;
  }

  // NOTA: buildLLMMessages, extractNameFromResponse e generateContext foram movidos
  // para VoiceIntelligence para centralizar a l√≥gica de intelig√™ncia do agente

  /**
   * Registra m√©tricas do turno
   */
  private recordTurnMetrics(session: CallSession): void {
    if (!this.currentMetrics) return;

    const m = this.currentMetrics;
    
    // Usar m√©tricas detalhadas do STT se dispon√≠veis
    const sttTiming = m.sttTimingMetrics;
    const sttRealLatency = sttTiming?.realLatency || (m.sttEnd - m.sttStart);
    
    const latency: LatencyBreakdown = {
      // Usar lat√™ncia REAL do STT (tempo at√© primeira parcial)
      stt: sttRealLatency,
      llm: (m.llmFirstToken || m.playbackEnd) - m.llmStart,
      tts: m.ttsFirstChunk ? m.ttsFirstChunk - m.ttsStart : 0,
      // Total = STT real + LLM + TTS (sem contar tempo de fala do usu√°rio)
      total: sttRealLatency + ((m.llmFirstToken || m.playbackEnd) - m.llmStart) + (m.ttsFirstChunk ? m.ttsFirstChunk - m.ttsStart : 0),
      timeToFirstAudio: m.playbackStart ? m.playbackStart - m.sttEnd : 0,
      // Novas m√©tricas separadas
      speechDuration: sttTiming?.speechDuration,
      vadDelay: sttTiming?.vadWaitTime,
    };

    const turnMetrics: TurnMetrics = {
      turnId: m.turnId,
      timestamp: new Date(),
      latency,
      audioInputDuration: sttTiming?.speechDuration || 0,
      audioOutputDuration: 0,
      fillerUsed: false,
    };

    session.metrics.turns.push(turnMetrics);
    this.updateAggregateMetrics(session);

    // Log m√©tricas com separa√ß√£o clara entre lat√™ncia e tempo de fala
    this.logger.info('üìä M√©tricas do turno:');
    this.logger.info(`   ‚ö° Lat√™ncias: STT=${latency.stt}ms | LLM=${latency.llm}ms | TTS=${latency.tts}ms`);
    if (latency.speechDuration !== undefined) {
      this.logger.info(`   üó£Ô∏è Info: Dura√ß√£o da fala=${latency.speechDuration}ms | VAD wait=${latency.vadDelay}ms`);
    }
    this.logger.info(`   ‚è±Ô∏è Time to First Audio: ${latency.timeToFirstAudio}ms`);
    this.logger.info(`   üìà Total (lat√™ncia real): ${latency.total}ms ${m.interrupted ? '(interrompido)' : ''}`);

    // An√°lise de gargalos (apenas se lat√™ncia estiver alta)
    if (latency.total > 2000 || latency.timeToFirstAudio > 2000) {
      const analyzer = new LatencyAnalyzer();
      analyzer.logAnalysis(latency);
    }

    this.emit('metrics', m.turnId, latency);
  }

  /**
   * Atualiza m√©tricas agregadas
   */
  private updateAggregateMetrics(session: CallSession): void {
    const turns = session.metrics.turns;
    if (turns.length === 0) return;

    const sum = turns.reduce(
      (acc, t) => ({
        stt: acc.stt + t.latency.stt,
        llm: acc.llm + t.latency.llm,
        tts: acc.tts + t.latency.tts,
        total: acc.total + t.latency.total,
        timeToFirstAudio: acc.timeToFirstAudio + t.latency.timeToFirstAudio,
      }),
      { stt: 0, llm: 0, tts: 0, total: 0, timeToFirstAudio: 0 }
    );

    session.metrics.averageLatency = {
      stt: Math.round(sum.stt / turns.length),
      llm: Math.round(sum.llm / turns.length),
      tts: Math.round(sum.tts / turns.length),
      total: Math.round(sum.total / turns.length),
      timeToFirstAudio: Math.round(sum.timeToFirstAudio / turns.length),
    };
  }

  /**
   * Encerra a sess√£o
   */
  async endSession(callId: string): Promise<CallSummary | null> {
    const session = this.activeSessions.get(callId);
    if (!session) return null;

    session.status = 'ended';
    session.endedAt = new Date();
    session.metrics.totalDuration = session.endedAt.getTime() - session.startedAt.getTime();

    await this.config.localProvider.endCall(callId);

    const summary: CallSummary = {
      callId,
      duration: session.metrics.totalDuration,
      turns: session.conversationHistory.length,
      outcome: 'not_interested',
      metrics: session.metrics,
      transcript: session.conversationHistory,
    };

    // Parar AudioRoom (grava√ß√£o de √°udio mixada)
    if (this.audioRoom) {
      await this.audioRoom.stop();
      this.audioRoom = null;
    }
    
    // Salvar transcri√ß√£o da chamada
    if (this.callRecorder) {
      const recordingMetrics = {
        averageSTT: session.metrics.averageLatency.stt,
        averageLLM: session.metrics.averageLatency.llm,
        averageTTS: session.metrics.averageLatency.tts,
        averageTimeToFirstAudio: session.metrics.averageLatency.timeToFirstAudio,
      };
      const recordingPath = await this.callRecorder.stop(recordingMetrics);
      if (recordingPath) {
        this.logger.info(`üìÅ Grava√ß√£o salva em: ${recordingPath}`);
      }
      this.callRecorder = null;
    }

    // Limpar m√≥dulos de gerenciamento de estado
    this.turnState.clearSession(callId);
    this.echoFilter.clearSession(callId);
    this.acknowledgmentManager.clearSession(callId);
    this.greetingTranscription = ''; // Limpar transcri√ß√£o guardada da sauda√ß√£o

    this.activeSessions.delete(callId);
    this.emit('session:ended', callId, summary);

    this.logger.info('üìä Resumo da sess√£o:');
    this.logger.info(`   Dura√ß√£o: ${Math.round(summary.duration / 1000)}s`);
    this.logger.info(`   Turnos: ${summary.turns}`);
    this.logger.info(`   Lat√™ncia m√©dia: STT=${session.metrics.averageLatency.stt}ms, LLM=${session.metrics.averageLatency.llm}ms`);
    this.logger.info(`   Time to First Audio m√©dio: ${session.metrics.averageLatency.timeToFirstAudio}ms`);

    return summary;
  }

  /**
   * Retorna sess√£o ativa
   */
  getSession(callId: string): CallSession | undefined {
    return this.activeSessions.get(callId);
  }
}
