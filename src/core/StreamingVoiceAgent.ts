/**
 * StreamingVoiceAgent - Orquestrador de voz com streaming
 * 
 * ResponsÃ¡vel por:
 * - Pipeline de streaming: LLM gera texto â†’ TTS gera Ã¡udio â†’ reproduz imediatamente
 * - Menor latÃªncia possÃ­vel (Time to First Audio)
 * - Suporte a barge-in (interrupÃ§Ã£o)
 * - MÃ©tricas de latÃªncia detalhadas
 */

import { EventEmitter } from 'events';
import {
  VoiceAgentConfig,
  CallSession,
  ConversationTurn,
  TurnMetrics,
  FillerContext,
  CallSummary,
  LatencyBreakdown,
  ITranscriber,
  ILLM,
  ITTS,
  IFillerManager,
  IMetricsCollector,
  TranscriptionResult,
  STTTimingMetrics,
} from '../types';
import { Logger } from '../utils/Logger';
import { LocalAudioProvider } from '../providers/LocalAudioProvider';
import { ContextualFillerManager } from './ContextualFillerManager';
import { LatencyAnalyzer } from '../utils/LatencyAnalyzer';
import { CallRecorder } from '../utils/CallRecorder';
import { AudioRoom } from '../utils/AudioRoom';
import { config as appConfig, generatePhaseContext } from '../config';
import { ThinkingEngine } from './ThinkingEngine';

// ConfiguraÃ§Ãµes de streaming
const STREAMING_CONFIG = {
  MIN_CHARS_FOR_TTS: 15,          // MÃ­nimo de caracteres antes de enviar para TTS
  SENTENCE_DELIMITERS: ['.', '!', '?', ':', ';', ','], // Delimitadores de frase
  MAX_BUFFER_CHARS: 50,           // MÃ¡ximo de caracteres no buffer antes de forÃ§ar flush
};

interface StreamingVoiceAgentConfig {
  transcriber: ITranscriber;
  llm: ILLM;
  tts: ITTS;
  fillerManager?: IFillerManager;
  metrics?: IMetricsCollector;
  systemPrompt: string;
  localProvider: LocalAudioProvider;
}

interface StreamingMetrics {
  turnId: string;
  sttStart: number;
  sttEnd: number;
  llmStart: number;
  llmFirstToken: number;
  ttsStart: number;
  ttsFirstChunk: number;
  playbackStart: number;
  playbackEnd: number;
  totalTokens: number;
  interrupted: boolean;
  // MÃ©tricas detalhadas do STT (separadas de speechDuration e vadDelay)
  sttTimingMetrics?: STTTimingMetrics;
}

export class StreamingVoiceAgent extends EventEmitter {
  private config: StreamingVoiceAgentConfig;
  private logger: Logger;
  private activeSessions: Map<string, CallSession> = new Map();
  private currentMetrics: StreamingMetrics | null = null;
  private isProcessing: boolean = false;
  private isGreetingInProgress: boolean = false; // Bloqueia processamento durante saudaÃ§Ã£o
  private useStreamingSTT: boolean = false; // Usa STT em streaming (Scribe)
  private contextualFillerManager: ContextualFillerManager | null = null; // Fillers contextualizados (desabilitados por enquanto)
  private wasInterrupted: boolean = false; // Flag para indicar que houve barge-in
  private bargeInTimestamp: number = 0; // Timestamp do Ãºltimo barge-in
  private static readonly BARGE_IN_GRACE_PERIOD_MS = 800; // Ignorar transcriÃ§Ãµes por 800ms apÃ³s barge-in
  private pendingTranscriptionCallId: string | null = null; // CallId da transcriÃ§Ã£o que estÃ¡ sendo processada
  
  // PrÃ©-processamento com transcriÃ§Ãµes parciais
  private lastPartialText: string = '';
  private lastPartialTime: number = 0;
  private prebuiltLLMContext: Array<{ role: 'system' | 'user' | 'assistant'; content: string }> | null = null;
  private partialSentenceComplete: boolean = false; // Indica se detectamos fim de frase na parcial

  // GravaÃ§Ã£o de chamadas
  private callRecorder: CallRecorder | null = null;
  private audioRoom: AudioRoom | null = null;

  // Engine de pensamentos internos (opcional - controlado por ENABLE_THINKING_ENGINE)
  private thinkingEngine: ThinkingEngine | null = null;

  constructor(config: StreamingVoiceAgentConfig) {
    super();
    this.config = config;
    this.logger = new Logger('StreamingAgent');
    
    // Detectar se o transcriber suporta streaming
    this.useStreamingSTT = !!(
      this.config.transcriber.startStream &&
      this.config.transcriber.feedAudio &&
      this.config.transcriber.onTranscript
    );
    
    if (this.useStreamingSTT) {
      this.logger.info('ğŸš€ Modo STT: Streaming (ElevenLabs Scribe)');
      
      // Inicializar gerador de fillers contextualizados
      this.contextualFillerManager = new ContextualFillerManager({
        llm: this.config.llm,
        tts: this.config.tts,
        useQuickLLM: false, // Usar templates (mais rÃ¡pido). Mude para true para LLM
      });
      this.logger.info('ğŸ¯ Fillers contextualizados habilitados');
    } else {
      this.logger.info('ğŸ“¦ Modo STT: Batch (OpenAI Whisper)');
    }

    // Inicializar engine de pensamentos internos (se habilitado)
    if (appConfig.thinkingEngine.enabled) {
      this.thinkingEngine = new ThinkingEngine({
        llm: this.config.llm,
      });
      this.logger.info('ğŸ§  ThinkingEngine habilitado (ENABLE_THINKING_ENGINE=true)');
    } else {
      this.logger.info('ğŸ’­ ThinkingEngine desabilitado (ENABLE_THINKING_ENGINE=false)');
    }
  }

  /**
   * Inicia uma sessÃ£o de conversa local
   */
  async startLocalSession(prospectData?: { name?: string; company?: string }): Promise<string> {
    const callId = await this.config.localProvider.makeCall('+5511999999999');
    
    const session: CallSession = {
      id: callId,
      phoneNumber: 'local',
      prospectName: prospectData?.name || undefined, // NÃ£o definir nome inicialmente - serÃ¡ coletado
      companyName: prospectData?.company || undefined,
      startedAt: new Date(),
      status: 'active',
      conversationHistory: [],
      metrics: {
        totalDuration: 0,
        turns: [],
        averageLatency: { stt: 0, llm: 0, tts: 0, total: 0, timeToFirstAudio: 0 },
        peakLatency: { stt: 0, llm: 0, tts: 0, total: 0, timeToFirstAudio: 0 },
        fillersUsed: 0,
        transcriptionErrors: 0,
      },
      internalThoughts: [], // Inicializar array de pensamentos internos
    };

    this.activeSessions.set(callId, session);
    
    // Inicializar gravador de chamadas (para transcriÃ§Ãµes)
    this.callRecorder = new CallRecorder(callId);
    this.callRecorder.start();
    
    // Inicializar AudioRoom (para gravaÃ§Ã£o de Ã¡udio mixada)
    const recordingPath = this.callRecorder.getRecordingFolder();
    if (recordingPath) {
      this.audioRoom = new AudioRoom();
      this.audioRoom.start(`${recordingPath}/call_recording.wav`);
    }
    
    // Configurar modo de VAD baseado no tipo de STT
    if (this.useStreamingSTT) {
      // MODO STREAMING (Scribe): VAD externo, chunks enviados diretamente
      this.config.localProvider.setVADMode('external');
      
      // Iniciar stream do transcriber com retry em caso de erro
      try {
        await this.config.transcriber.startStream!(callId);
      } catch (error) {
        this.logger.error('âŒ Erro ao iniciar Scribe, tentando reconectar...', error);
        // Tentar reconectar apÃ³s 1 segundo
        await new Promise(resolve => setTimeout(resolve, 1000));
        try {
          await this.config.transcriber.startStream!(callId);
          this.logger.info('âœ… Reconectado ao Scribe apÃ³s erro');
        } catch (retryError) {
          this.logger.error('âŒ Falha ao reconectar Scribe:', retryError);
          throw retryError;
        }
      }
      
      // Callback para chunks de Ã¡udio - envia diretamente para o Scribe
      this.config.localProvider.onAudioChunk(callId, (chunk: Buffer) => {
        // Gravar Ã¡udio do usuÃ¡rio no AudioRoom
        if (this.audioRoom) {
          this.audioRoom.feedUserAudio(chunk);
        }
        
        if (!this.isGreetingInProgress) {
          // Verificar se Scribe ainda estÃ¡ conectado antes de enviar
          if (this.config.transcriber.feedAudio) {
            // Verificar conexÃ£o antes de enviar (se mÃ©todo disponÃ­vel)
            const scribe = this.config.transcriber as any;
            if (scribe.isStreamConnected && !scribe.isStreamConnected()) {
              this.logger.warn('âš ï¸ Scribe desconectado, tentando reconectar...');
              // Tentar reconectar em background (nÃ£o bloquear)
              this.config.transcriber.startStream!(callId).catch(err => {
                this.logger.error('Erro ao reconectar Scribe:', err);
              });
              return;
            }
            this.config.transcriber.feedAudio(callId, chunk);
          } else {
            this.logger.warn('âš ï¸ Scribe feedAudio nÃ£o disponÃ­vel - chunks nÃ£o serÃ£o enviados');
          }
        }
      });
      
      // Callback para transcriÃ§Ãµes finais do Scribe
      this.config.transcriber.onTranscript!(callId, async (result) => {
        if (!this.isGreetingInProgress && !this.isProcessing) {
          this.logger.debug(`ğŸ“ Recebida transcriÃ§Ã£o do Scribe: "${result.text}"`);
          await this.processTranscription(callId, result);
        } else {
          this.logger.debug(`âš ï¸ TranscriÃ§Ã£o ignorada - greeting: ${this.isGreetingInProgress}, processing: ${this.isProcessing}`);
        }
      });
      
      // Listener para erros do Scribe (se EventEmitter)
      const scribe = this.config.transcriber as any;
      if (scribe.on && typeof scribe.on === 'function') {
        scribe.on('error', (error: Error) => {
          this.logger.error('âŒ Erro do Scribe:', error);
          // Tentar reconectar automaticamente
          if (!this.isGreetingInProgress) {
            this.logger.info('ğŸ”„ Tentando reconectar Scribe...');
            this.config.transcriber.startStream!(callId).catch(err => {
              this.logger.error('Erro ao reconectar Scribe:', err);
            });
          }
        });
      }
      
      // Callback para transcriÃ§Ãµes parciais - com prÃ©-processamento para menor latÃªncia
      if (this.config.transcriber.onPartialTranscript) {
        this.config.transcriber.onPartialTranscript(callId, (text) => {
          this.emit('partial:transcript', callId, text);
          
          // PrÃ©-processamento: detectar possÃ­vel fim de frase e prÃ©-construir contexto LLM
          if (!this.isProcessing && !this.isGreetingInProgress && text.length > 5) {
            this.handlePartialTranscriptForPreprocessing(callId, text);
          }
        });
      }
    } else {
      // MODO BATCH (Whisper): VAD interno, Ã¡udio acumulado
      this.config.localProvider.setVADMode('internal');
      
      // Callback de Ã¡udio apÃ³s VAD detectar fim da fala
      this.config.localProvider.onAudioReceived(callId, async (audio: Buffer) => {
        await this.processStreamingTurn(callId, audio);
      });
    }

    // Listener para barge-in
    this.config.localProvider.on('playback:interrupted', (interruptedCallId: string) => {
      this.wasInterrupted = true;
      this.bargeInTimestamp = Date.now();
      
      if (this.currentMetrics) {
        this.currentMetrics.interrupted = true;
      }
      
      this.logger.info('ğŸ”‡ Barge-in detectado - cancelando TODOS os processamentos');
      
      // Interromper gravaÃ§Ã£o do agente no AudioRoom (descartar segmento atual)
      if (this.audioRoom) {
        this.audioRoom.interruptAgent();
      }
      
      // IMPORTANTE: Resetar timers de latÃªncia do STT para mÃ©tricas corretas
      // Isso evita que o tempo de Ã¡udio enviado durante fala do agente seja contado como latÃªncia
      const scribe = this.config.transcriber as any;
      if (scribe.resetTimingOnBargeIn) {
        scribe.resetTimingOnBargeIn();
      }
      if (scribe.setAgentSpeaking) {
        scribe.setAgentSpeaking(false); // Agente parou de falar (foi interrompido)
      }
      
      // Cancelar processamento atual se estiver em andamento
      if (this.isProcessing) {
        this.logger.warn('âš ï¸ Cancelando processamento em andamento devido a barge-in');
        this.isProcessing = false;
      }
      
      // Se houver transcriÃ§Ã£o pendente, marcar para ignorar
      if (this.pendingTranscriptionCallId) {
        this.logger.warn(`âš ï¸ Ignorando transcriÃ§Ã£o pendente de ${this.pendingTranscriptionCallId} devido a barge-in`);
        this.pendingTranscriptionCallId = null;
      }
      
      // Auto-reset do flag apÃ³s grace period
      setTimeout(() => {
        if (this.bargeInTimestamp > 0 && Date.now() - this.bargeInTimestamp >= StreamingVoiceAgent.BARGE_IN_GRACE_PERIOD_MS) {
          this.wasInterrupted = false;
          this.bargeInTimestamp = 0;
          this.logger.debug('âœ… Flag de barge-in auto-resetada apÃ³s grace period');
        }
      }, StreamingVoiceAgent.BARGE_IN_GRACE_PERIOD_MS + 100);
    });

    // Iniciar gravaÃ§Ã£o
    await this.config.localProvider.startRecording(callId);

    this.emit('session:started', callId);
    this.logger.info(`âœ… SessÃ£o ${callId} iniciada - Fale algo!`);

    // Gerar saudaÃ§Ã£o inicial (bloqueia processamento de Ã¡udio)
    this.isGreetingInProgress = true;
    await this.generateGreeting(callId);
    this.isGreetingInProgress = false;

    return callId;
  }

  /**
   * Gera saudaÃ§Ã£o inicial - Simula ligaÃ§Ã£o de vendas
   * Primeiro coleta o nome, depois se apresenta
   */
  private async generateGreeting(callId: string): Promise<void> {
    const session = this.activeSessions.get(callId);
    if (!session) return;

    this.logger.info('ğŸ“ Gerando abertura da ligaÃ§Ã£o...');

    // Usar prompt de saudaÃ§Ã£o do config
    const greetingPrompt = appConfig.agent.greetingPrompt
      .replace('{prospectName}', session.prospectName || 'Ainda nÃ£o coletado - vocÃª precisa perguntar')
      .replace('{companyName}', session.companyName || 'NÃ£o informada');

    const greetingMessages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }> = [
      { role: 'system', content: greetingPrompt },
    ];

    // Gerar saudaÃ§Ã£o com streaming
    await this.streamLLMToTTS(callId, greetingMessages, session);
  }

  /**
   * Toca um filler GENÃ‰RICO imediatamente (antes de saber o que o usuÃ¡rio disse)
   * Usado em paralelo com STT para dar feedback instantÃ¢neo
   */
  private async playFillerGeneric(callId: string, session: CallSession): Promise<void> {
    if (!this.config.fillerManager) {
      return; // Fillers nÃ£o configurados
    }

    try {
      const conversationStage = this.detectConversationStage(session);
      
      // Usar filler genÃ©rico (nÃ£o sabemos ainda o que o usuÃ¡rio disse)
      const filler = this.config.fillerManager.getFiller({
        conversationStage,
        prospectName: session.prospectName,
        // Sem lastUserMessage - forÃ§a filler genÃ©rico
      });

      if (filler) {
        this.logger.info(`ğŸµ Tocando filler: "${filler.text}"`);
        await this.config.localProvider.sendAudio(callId, filler.audioBuffer);
        session.metrics.fillersUsed++;
      }
    } catch (error) {
      // Falha no filler nÃ£o deve interromper o fluxo
      this.logger.warn('Erro ao tocar filler:', error);
    }
  }

  /**
   * Detecta o estÃ¡gio da conversa baseado no histÃ³rico
   */
  private detectConversationStage(session: CallSession): 'intro' | 'qualifying' | 'presenting' | 'closing' {
    const turns = session.conversationHistory.length;
    
    if (turns <= 2) return 'intro';
    if (turns <= 6) return 'qualifying';
    if (turns <= 12) return 'presenting';
    return 'closing';
  }

  /**
   * PrÃ©-processa transcriÃ§Ãµes parciais para reduzir latÃªncia
   * Detecta padrÃµes de fim de frase e prÃ©-constrÃ³i contexto do LLM
   */
  private handlePartialTranscriptForPreprocessing(callId: string, partialText: string): void {
    const now = Date.now();
    const session = this.activeSessions.get(callId);
    if (!session) return;

    // Detectar se parece fim de frase (pontuaÃ§Ã£o ou pausa)
    const trimmedText = partialText.trim();
    const endsWithPunctuation = /[.!?]$/.test(trimmedText);
    const timeSinceLastPartial = now - this.lastPartialTime;
    const hasSignificantPause = this.lastPartialTime > 0 && timeSinceLastPartial > 200;
    
    // Atualizar estado da transcriÃ§Ã£o parcial
    this.lastPartialText = trimmedText;
    this.lastPartialTime = now;

    // Se detectamos possÃ­vel fim de frase, prÃ©-construir contexto do LLM
    if ((endsWithPunctuation || hasSignificantPause) && trimmedText.length >= 10) {
      // Criar cÃ³pia temporÃ¡ria do histÃ³rico com a transcriÃ§Ã£o parcial
      const tempHistory = [...session.conversationHistory];
      tempHistory.push({
        role: 'user',
        content: trimmedText,
        timestamp: new Date(),
      });

      // Construir mensagens para o LLM usando histÃ³rico temporÃ¡rio
      const tempSession = { ...session, conversationHistory: tempHistory };
      this.prebuiltLLMContext = this.buildLLMMessages(tempSession);
      this.partialSentenceComplete = true;
      
      this.logger.debug(`âš¡ PrÃ©-processamento: contexto LLM prÃ©-construÃ­do para "${trimmedText.substring(0, 30)}..."`);
    }
  }

  /**
   * Reseta estado de prÃ©-processamento
   */
  private resetPreprocessingState(): void {
    this.lastPartialText = '';
    this.lastPartialTime = 0;
    this.prebuiltLLMContext = null;
    this.partialSentenceComplete = false;
  }

  /**
   * Processa um turno de conversa com streaming completo
   */
  async processStreamingTurn(callId: string, userAudio: Buffer): Promise<void> {
    const session = this.activeSessions.get(callId);
    if (!session) {
      this.logger.error(`SessÃ£o nÃ£o encontrada: ${callId}`);
      return;
    }

    // Ignorar Ã¡udio durante a saudaÃ§Ã£o inicial
    if (this.isGreetingInProgress) {
      this.logger.debug('SaudaÃ§Ã£o em andamento, ignorando Ã¡udio...');
      return;
    }

    // Ignorar Ã¡udio enquanto o agente estÃ¡ falando (evita processar enquanto reproduz)
    if (this.config.localProvider.isCurrentlyPlaying()) {
      this.logger.debug('Agente ainda falando, ignorando Ã¡udio...');
      return;
    }

    if (this.isProcessing) {
      this.logger.debug('JÃ¡ processando, ignorando...');
      return;
    }

    this.isProcessing = true;
    const turnId = `turn-${Date.now()}`;

    // Inicializar mÃ©tricas
    this.currentMetrics = {
      turnId,
      sttStart: Date.now(),
      sttEnd: 0,
      llmStart: 0,
      llmFirstToken: 0,
      ttsStart: 0,
      ttsFirstChunk: 0,
      playbackStart: 0,
      playbackEnd: 0,
      totalTokens: 0,
      interrupted: false,
    };

    try {
      // ============================================
      // FASE 1: Speech-to-Text
      // ============================================
      this.logger.info('ğŸ“ Transcrevendo...');
      
      const transcription = await this.config.transcriber.transcribe(userAudio);
      this.currentMetrics.sttEnd = Date.now();
      
      const sttDuration = this.currentMetrics.sttEnd - this.currentMetrics.sttStart;
      this.logger.info(`ğŸ“ STT (${sttDuration}ms): "${transcription.text}"`);

      // Validar transcriÃ§Ã£o
      if (!transcription.text || transcription.text.trim().length < 2) {
        this.logger.warn('TranscriÃ§Ã£o muito curta, ignorando turno');
        this.isProcessing = false;
        return;
      }

      // Adicionar ao histÃ³rico
      session.conversationHistory.push({
        role: 'user',
        content: transcription.text,
        timestamp: new Date(),
      });

      this.emit('user:spoke', callId, transcription.text);

      // ============================================
      // FASE 2: LLM Streaming â†’ TTS Streaming â†’ Play
      // ============================================
      const messages = this.buildLLMMessages(session);
      await this.streamLLMToTTS(callId, messages, session);

      // ============================================
      // FASE 3: Calcular mÃ©tricas
      // ============================================
      this.currentMetrics.playbackEnd = Date.now();
      this.recordTurnMetrics(session);

    } catch (error) {
      this.logger.error(`Erro no turno ${turnId}:`, error);
      this.emit('error', error, `turn:${turnId}`);
    } finally {
      this.isProcessing = false;
    }
  }

  /**
   * Processa uma transcriÃ§Ã£o jÃ¡ pronta (modo streaming - Scribe)
   * Pula a etapa de STT pois o Scribe jÃ¡ transcreveu via streaming
   */
  async processTranscription(callId: string, transcription: TranscriptionResult): Promise<void> {
    const session = this.activeSessions.get(callId);
    if (!session) {
      this.logger.error(`SessÃ£o nÃ£o encontrada: ${callId}`);
      return;
    }

    // Ignorar durante saudaÃ§Ã£o
    if (this.isGreetingInProgress) {
      return;
    }

    // Verificar se houve barge-in ANTES de qualquer processamento
    // Usar timestamp para garantir que o grace period seja respeitado
    const timeSinceBargeIn = Date.now() - this.bargeInTimestamp;
    if (this.wasInterrupted && timeSinceBargeIn < StreamingVoiceAgent.BARGE_IN_GRACE_PERIOD_MS) {
      this.logger.debug(`âš ï¸ Ignorando transcriÃ§Ã£o devido a barge-in recente (${timeSinceBargeIn}ms atrÃ¡s)`);
      return;
    }
    
    // Resetar flag se passou o grace period
    if (this.wasInterrupted && timeSinceBargeIn >= StreamingVoiceAgent.BARGE_IN_GRACE_PERIOD_MS) {
      this.wasInterrupted = false;
      this.bargeInTimestamp = 0;
      this.logger.debug('âœ… Flag de barge-in resetada (grace period expirado)');
    }

    // Ignorar enquanto agente fala (a menos que tenha sido interrompido)
    if (this.config.localProvider.isCurrentlyPlaying()) {
      this.logger.debug('Agente ainda falando, ignorando transcriÃ§Ã£o...');
      return;
    }

    if (this.isProcessing) {
      this.logger.debug('JÃ¡ processando, ignorando...');
      return;
    }
    
    // VerificaÃ§Ã£o adicional: se houve barge-in durante o check acima, cancelar
    if (this.wasInterrupted) {
      this.logger.debug('âš ï¸ Barge-in detectado durante verificaÃ§Ã£o, cancelando');
      return;
    }

    // Marcar transcriÃ§Ã£o como pendente
    this.pendingTranscriptionCallId = callId;
    this.isProcessing = true;
    const turnId = `turn-${Date.now()}`;

    // MÃ©tricas - STT jÃ¡ aconteceu via streaming
    // Usar mÃ©tricas detalhadas do Scribe se disponÃ­veis
    const timingMetrics = transcription.timingMetrics;
    const sttRealLatency = timingMetrics?.realLatency || transcription.duration || 0;
    
    // IMPORTANTE: sttEnd = momento atual (quando a transcriÃ§Ã£o final chegou)
    // Isso Ã© o ponto de referÃªncia para Time to First Audio
    const now = Date.now();
    
    this.currentMetrics = {
      turnId,
      sttStart: timingMetrics?.startTime || now - sttRealLatency,
      sttEnd: now, // Momento que a transcriÃ§Ã£o final chegou (inÃ­cio do processamento LLM)
      llmStart: 0,
      llmFirstToken: 0,
      ttsStart: 0,
      ttsFirstChunk: 0,
      playbackStart: 0,
      playbackEnd: 0,
      totalTokens: 0,
      interrupted: false,
      sttTimingMetrics: timingMetrics, // Guardar mÃ©tricas detalhadas
    };

    const transcriptText = transcription.text.trim();
    
    // Ignorar apenas transcriÃ§Ãµes extremamente curtas (ruÃ­do)
    // Respostas de 1 palavra como "Sim", "NÃ£o", "Isso", "Ok" sÃ£o vÃ¡lidas
    if (transcriptText.length < 2) {
      this.logger.debug(`Ignorando transcriÃ§Ã£o muito curta: "${transcriptText}"`);
      this.isProcessing = false;
      this.pendingTranscriptionCallId = null;
      return;
    }
    
    // Log com mÃ©tricas separadas
    if (timingMetrics) {
      this.logger.info(`ğŸ“ STT Scribe:`);
      this.logger.info(`   âš¡ LatÃªncia REAL: ${timingMetrics.realLatency}ms (target: <300ms)`);
      this.logger.info(`   ğŸ—£ï¸ DuraÃ§Ã£o da fala: ${timingMetrics.speechDuration}ms (nÃ£o Ã© latÃªncia)`);
      this.logger.info(`   â±ï¸ VAD wait: ${timingMetrics.vadWaitTime}ms`);
      this.logger.info(`   ğŸ“ Texto: "${transcriptText}"`);
    } else {
      this.logger.info(`ğŸ“ STT Scribe (${sttRealLatency}ms): "${transcriptText}"`);
    }

    try {
      // Verificar barge-in novamente antes de processar (pode ter acontecido durante validaÃ§Ã£o)
      if (this.wasInterrupted) {
        this.logger.debug('âš ï¸ Barge-in detectado antes de processar, cancelando');
        this.isProcessing = false;
        this.pendingTranscriptionCallId = null;
        return;
      }

      // Fillers genÃ©ricos desabilitados - causavam pausas estranhas
      // Apenas fillers contextuais (baseados em transcriÃ§Ãµes parciais) sÃ£o usados

      // Adicionar ao histÃ³rico (jÃ¡ validado acima)
      session.conversationHistory.push({
        role: 'user',
        content: transcriptText,
        timestamp: new Date(),
      });
      
      // Gravar transcriÃ§Ã£o do usuÃ¡rio
      if (this.callRecorder) {
        this.callRecorder.addTranscriptEntry('user', transcriptText);
      }

      // Tentar extrair nome se ainda nÃ£o tiver coletado
      if (!session.prospectName || session.prospectName === 'Visitante' || session.prospectName.length < 2) {
        this.logger.debug(`ğŸ” Tentando extrair nome de: "${transcriptText}"`);
        const extractedName = this.extractNameFromResponse(transcriptText);
        if (extractedName) {
          session.prospectName = extractedName;
          this.logger.info(`âœ… Nome coletado: ${extractedName}`);
        } else {
          this.logger.debug(`âš ï¸ Nome nÃ£o extraÃ­do de: "${transcriptText}"`);
        }
      }

      this.emit('user:spoke', callId, transcriptText);

      // Verificar barge-in antes de gerar resposta
      if (this.wasInterrupted) {
        this.logger.debug('âš ï¸ Barge-in detectado antes de gerar resposta, cancelando');
        this.isProcessing = false;
        this.pendingTranscriptionCallId = null;
        this.resetPreprocessingState();
        return;
      }

      // LLM â†’ TTS â†’ Play
      // Usar contexto prÃ©-construÃ­do se disponÃ­vel e texto for similar
      let messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }>;
      
      if (this.prebuiltLLMContext && this.partialSentenceComplete && 
          this.lastPartialText && transcriptText.includes(this.lastPartialText.substring(0, 20))) {
        // Usar contexto prÃ©-construÃ­do (economiza tempo de construÃ§Ã£o)
        messages = this.prebuiltLLMContext;
        // Atualizar a Ãºltima mensagem do usuÃ¡rio com o texto final completo
        const lastMessage = messages[messages.length - 1];
        if (lastMessage && lastMessage.role === 'user') {
          lastMessage.content = transcriptText;
        }
        this.logger.debug('âš¡ Usando contexto LLM prÃ©-construÃ­do');
      } else {
        // Construir contexto normalmente
        messages = this.buildLLMMessages(session);
      }
      
      // Resetar estado de prÃ©-processamento
      this.resetPreprocessingState();
      
      await this.streamLLMToTTS(callId, messages, session);

      // MÃ©tricas
      this.currentMetrics.playbackEnd = Date.now();
      this.recordTurnMetrics(session);

    } catch (error) {
      this.logger.error(`Erro no turno ${turnId}:`, error);
      this.emit('error', error, `turn:${turnId}`);
    } finally {
      this.isProcessing = false;
      this.pendingTranscriptionCallId = null;
      this.resetPreprocessingState(); // Garantir reset do estado de prÃ©-processamento
      // Flag de barge-in Ã© resetada automaticamente apÃ³s o grace period (800ms)
    }
  }

  /**
   * Gera resposta do LLM e sintetiza TTS com streaming REAL
   * 
   * FLUXO OTIMIZADO (streaming chunk por chunk):
   * 1. LLM comeÃ§a a gerar texto (streaming)
   * 2. Assim que tiver uma frase/clÃ¡usula completa, envia para TTS
   * 3. TTS sintetiza e envia Ã¡udio enquanto LLM continua gerando
   * 4. Reduz Time to First Audio significativamente
   */
  private async streamLLMToTTS(
    callId: string,
    messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }>,
    session: CallSession
  ): Promise<void> {
    if (!this.currentMetrics) {
      this.currentMetrics = {
        turnId: `greeting-${Date.now()}`,
        sttStart: Date.now(),
        sttEnd: Date.now(),
        llmStart: Date.now(),
        llmFirstToken: 0,
        ttsStart: 0,
        ttsFirstChunk: 0,
        playbackStart: 0,
        playbackEnd: 0,
        totalTokens: 0,
        interrupted: false,
      };
    }

    this.currentMetrics.llmStart = Date.now();
    
    let fullResponse = '';
    let isFirstAudio = true;
    let llmFirstTokenTime = 0;

    this.logger.info('ğŸ¤– Gerando resposta com streaming REAL...');
    
    // Resetar estado de interrupÃ§Ã£o para permitir nova reproduÃ§Ã£o
    this.currentMetrics.interrupted = false;
    this.config.localProvider.resetInterruptState();
    
    // Notificar STT que agente vai comeÃ§ar a falar (para mÃ©tricas corretas)
    const scribe = this.config.transcriber as any;
    if (scribe.setAgentSpeaking) {
      scribe.setAgentSpeaking(true);
    }
    
    // ===== STREAMING REAL: LLM â†’ TTS chunk por chunk =====
    // Delimitadores de sentenÃ§a/clÃ¡usula para dividir texto
    const SENTENCE_DELIMITERS = ['.', '!', '?'];
    const CLAUSE_DELIMITERS = [',', ';', ':'];
    const MIN_CHARS_FOR_TTS = 20; // MÃ­nimo de caracteres antes de enviar para TTS (aumentado para evitar fragmentaÃ§Ã£o)
    const MAX_BUFFER_CHARS = 80; // MÃ¡ximo de caracteres antes de forÃ§ar envio
    
    let textBuffer = ''; // Buffer de texto acumulado do LLM
    let chunkIndex = 0;
    
    // Fila de chunks de texto para processar SEQUENCIALMENTE (evita buffer underflow)
    const textChunkQueue: { text: string; isLast: boolean }[] = [];
    let isProcessingQueue = false;
    
    // FunÃ§Ã£o para processar a fila de chunks sequencialmente
    const processQueueSequentially = async (): Promise<void> => {
      if (isProcessingQueue) return; // JÃ¡ estÃ¡ processando
      isProcessingQueue = true;
      
      while (textChunkQueue.length > 0) {
        const item = textChunkQueue.shift()!;
        await processTextChunk(item.text, item.isLast);
      }
      
      isProcessingQueue = false;
    };
    
    // FunÃ§Ã£o para processar um chunk de texto no TTS
    const processTextChunk = async (text: string, isLast: boolean = false): Promise<void> => {
      if (!text.trim() || this.currentMetrics?.interrupted) return;
      
      const idx = chunkIndex++;
      this.logger.debug(`ğŸ“ TTS chunk ${idx}: "${text.substring(0, 30)}..."`);
      
      if (idx === 0) {
        this.currentMetrics!.ttsStart = Date.now();
      }
      
      try {
        if (!this.config.tts.synthesizeStream) {
          throw new Error('TTS nÃ£o suporta streaming');
        }
        
        await this.config.tts.synthesizeStream(text, async (audioChunk: Buffer) => {
          if (this.currentMetrics?.interrupted) return;

          if (isFirstAudio) {
            this.currentMetrics!.ttsFirstChunk = Date.now();
            this.currentMetrics!.playbackStart = Date.now();
            
            const timeToFirstAudio = this.currentMetrics!.ttsFirstChunk - this.currentMetrics!.sttEnd;
            this.logger.info(`âš¡ Time to First Audio: ${timeToFirstAudio}ms (LLM: ${llmFirstTokenTime - this.currentMetrics!.llmStart}ms)`);
            isFirstAudio = false;
          }

          // Gravar Ã¡udio do agente no AudioRoom
          if (this.audioRoom) {
            this.audioRoom.feedAgentAudio(audioChunk);
          }

          // Enviar para buffer de streaming
          await this.config.localProvider.sendAudioStream(callId, audioChunk);
        });
      } catch (error) {
        this.logger.error(`Erro no TTS chunk ${idx}:`, error);
      }
    };
    
    // Adicionar chunk Ã  fila e processar
    const enqueueTextChunk = (text: string, isLast: boolean = false): void => {
      textChunkQueue.push({ text, isLast });
      // Iniciar processamento se nÃ£o estiver rodando
      processQueueSequentially().catch(err => {
        this.logger.error('Erro ao processar fila TTS:', err);
      });
    };
    
    // Usar LLM com streaming real
    if (this.config.llm.generateStream) {
      try {
        const response = await this.config.llm.generateStream(messages, (chunk: string) => {
          if (this.currentMetrics?.interrupted) return;
          
          // Marcar primeiro token
          if (llmFirstTokenTime === 0) {
            llmFirstTokenTime = Date.now();
            this.currentMetrics!.llmFirstToken = llmFirstTokenTime;
          }
          
          fullResponse += chunk;
          textBuffer += chunk;
          
          // Verificar se temos uma sentenÃ§a completa (prioridade) ou clÃ¡usula
          const trimmedBuffer = textBuffer.trim();
          const lastChar = trimmedBuffer.slice(-1);
          const hasSentenceEnd = SENTENCE_DELIMITERS.includes(lastChar);
          const hasClauseEnd = CLAUSE_DELIMITERS.includes(lastChar);
          const hasEnoughChars = trimmedBuffer.length >= MIN_CHARS_FOR_TTS;
          const bufferFull = trimmedBuffer.length >= MAX_BUFFER_CHARS;
          
          // Enviar para TTS se:
          // 1. SentenÃ§a completa com chars suficientes, OU
          // 2. Buffer cheio (forÃ§ar envio)
          if ((hasSentenceEnd && hasEnoughChars) || bufferFull) {
            enqueueTextChunk(trimmedBuffer);
            textBuffer = '';
          }
          // ClÃ¡usula sÃ³ envia se buffer estÃ¡ quase cheio
          else if (hasClauseEnd && trimmedBuffer.length >= MAX_BUFFER_CHARS * 0.7) {
            enqueueTextChunk(trimmedBuffer);
            textBuffer = '';
          }
        });
        
        // Processar texto restante no buffer
        if (textBuffer.trim()) {
          enqueueTextChunk(textBuffer.trim(), true);
        }
        
        // Aguardar fila de TTS terminar
        while (textChunkQueue.length > 0 || isProcessingQueue) {
          await new Promise(resolve => setTimeout(resolve, 50));
        }
        
        const llmDuration = llmFirstTokenTime - this.currentMetrics.llmStart;
        this.logger.info(`âœ… LLM Streaming (${llmDuration}ms first token): "${fullResponse.substring(0, 50)}..."`);
        
      } catch (error) {
        this.logger.warn('Erro no LLM streaming, usando fallback batch:', error);
        // Fallback para modo batch
        const response = await this.config.llm.generate(messages, { maxTokens: 80 });
        fullResponse = response.text;
        this.currentMetrics.llmFirstToken = Date.now();
        await processTextChunk(fullResponse, true);
      }
    } else {
      // Fallback: LLM nÃ£o suporta streaming
      const response = await this.config.llm.generate(messages, { maxTokens: 80 });
      fullResponse = response.text;
      this.currentMetrics.llmFirstToken = Date.now();
      
      const llmDuration = this.currentMetrics.llmFirstToken - this.currentMetrics.llmStart;
      this.logger.info(`âœ… LLM Batch (${llmDuration}ms): "${fullResponse.substring(0, 50)}..."`);
      
      await processTextChunk(fullResponse, true);
    }

    // Finalizar streaming
    this.config.localProvider.endAudioStream();
    
    // Finalizar segmento de Ã¡udio do agente no AudioRoom
    if (this.audioRoom) {
      this.audioRoom.endAgentSegment();
    }
    
    // Notificar STT que agente parou de falar
    if (scribe.setAgentSpeaking) {
      scribe.setAgentSpeaking(false);
    }
    
    // Adicionar resposta ao histÃ³rico
    session.conversationHistory.push({
      role: 'agent',
      content: fullResponse,
      timestamp: new Date(),
    });
    
    // Gravar transcriÃ§Ã£o do agente
    if (this.callRecorder) {
      this.callRecorder.addTranscriptEntry('agent', fullResponse);
    }

    this.logger.info(`ğŸ¤– Resposta: "${fullResponse.substring(0, 80)}${fullResponse.length > 80 ? '...' : ''}"`);
    this.emit('agent:spoke', callId, fullResponse);

    // Disparar processamento de pensamentos em paralelo (nÃ£o bloqueia)
    // Aproveita o tempo de reproduÃ§Ã£o do Ã¡udio (~1-3s) enquanto o usuÃ¡rio ouve
    // SÃ³ processa se nÃ£o for saudaÃ§Ã£o inicial (tem mensagem do usuÃ¡rio) e se ThinkingEngine estiver habilitado
    if (this.thinkingEngine) {
      const userMessages = session.conversationHistory.filter(t => t.role === 'user');
      if (userMessages.length > 0) {
        this.processThoughtsInParallel(callId, session, fullResponse).catch(err => {
          this.logger.warn('Erro ao processar pensamentos (nÃ£o crÃ­tico):', err);
        });
      }
    }
  }

  /**
   * Processa pensamentos internos em paralelo (nÃ£o bloqueia)
   * Executa durante a reproduÃ§Ã£o do Ã¡udio para aproveitar tempo "morto"
   */
  private async processThoughtsInParallel(
    callId: string,
    session: CallSession,
    agentResponse: string
  ): Promise<void> {
    // Verificar se ThinkingEngine estÃ¡ habilitado
    if (!this.thinkingEngine) return;

    // Encontrar Ãºltima mensagem do usuÃ¡rio
    const userMessages = session.conversationHistory.filter(t => t.role === 'user');
    const lastUserMessage = userMessages.length > 0 
      ? userMessages[userMessages.length - 1].content 
      : '';

    if (!lastUserMessage) {
      // NÃ£o hÃ¡ mensagem do usuÃ¡rio ainda (pode ser saudaÃ§Ã£o inicial)
      return;
    }

    const turnId = this.currentMetrics?.turnId || `turn-${Date.now()}`;

    try {
      const thoughts = await this.thinkingEngine.processThoughts(
        session,
        lastUserMessage,
        agentResponse,
        turnId
      );

      if (thoughts) {
        // Inicializar array se nÃ£o existir
        if (!session.internalThoughts) {
          session.internalThoughts = [];
        }

        session.internalThoughts.push(thoughts);

        // Registrar no CallRecorder
        if (this.callRecorder) {
          this.callRecorder.addThoughts(thoughts);
        }

        this.logger.debug(`ğŸ’­ Pensamentos registrados para turno ${turnId}`);
      }
    } catch (error) {
      // Erro nÃ£o deve interromper o fluxo principal
      this.logger.warn('Erro ao processar pensamentos (nÃ£o crÃ­tico):', error);
    }
  }

  /**
   * Decide se deve enviar o buffer atual para TTS
   */
  private shouldFlushToTTS(buffer: string, lastChunk: string): boolean {
    // Se buffer atingiu tamanho mÃ¡ximo
    if (buffer.length >= STREAMING_CONFIG.MAX_BUFFER_CHARS) {
      return true;
    }

    // Se buffer tem tamanho mÃ­nimo E termina com delimitador
    if (buffer.length >= STREAMING_CONFIG.MIN_CHARS_FOR_TTS) {
      const lastChar = buffer.trim().slice(-1);
      if (STREAMING_CONFIG.SENTENCE_DELIMITERS.includes(lastChar)) {
        return true;
      }
    }

    return false;
  }

  /**
   * ConstrÃ³i mensagens para o LLM
   */
  private buildLLMMessages(session: CallSession): Array<{ role: 'system' | 'user' | 'assistant'; content: string }> {
    let systemPrompt = this.config.systemPrompt
      .replace('{prospectName}', session.prospectName || 'Ainda nÃ£o coletado')
      .replace('{companyName}', session.companyName || 'NÃ£o informada')
      .replace('{context}', this.generateContext(session));

    // Adicionar pensamentos anteriores ao contexto (Ãºltimos 2)
    if (session.internalThoughts && session.internalThoughts.length > 0) {
      const recentThoughts = session.internalThoughts.slice(-2);
      const thoughtsContext = ThinkingEngine.formatThoughtsForContext(recentThoughts);
      
      if (thoughtsContext) {
        systemPrompt += `\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ’­ SEUS PENSAMENTOS ANTERIORES (use para manter coerÃªncia no raciocÃ­nio):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
${thoughtsContext}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`;
      }
    }

    const messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }> = [
      { role: 'system', content: systemPrompt },
    ];

    // Adicionar histÃ³rico recente (6 para prompt slim, 10 para normal)
    const historyLimit = appConfig.agent.useSlimPrompt ? -6 : -10;
    const recentHistory = session.conversationHistory.slice(historyLimit);
    for (const turn of recentHistory) {
      messages.push({
        role: turn.role === 'agent' ? 'assistant' : 'user',
        content: turn.content,
      });
    }

    return messages;
  }

  /**
   * Extrai nome da resposta do usuÃ¡rio
   * Tenta identificar padrÃµes como "Meu nome Ã© X", "Sou o X", "Eu sou X", etc.
   */
  private extractNameFromResponse(text: string): string | null {
    const lower = text.toLowerCase().trim();
    
    // Palavras comuns que NÃƒO sÃ£o nomes (lista expandida)
    const commonWords = [
      // Respostas curtas
      'sim', 'nÃ£o', 'ok', 'tÃ¡', 'ah', 'oi', 'olÃ¡', 'bom', 'boa', 'tarde', 'dia', 'noite',
      // ConjunÃ§Ãµes e preposiÃ§Ãµes
      'se', 'for', 'como', 'Ã©', 'o', 'a', 'de', 'da', 'do', 'que', 'qual', 'quando', 'onde', 'quem',
      // Verbos comuns
      'posso', 'cair', 'tudo', 'bem', 'meu', 'minha', 'sou', 'estou', 'falo', 'fala',
      'pode', 'fazer', 'faz', 'estÃ¡', 'estÃ£o', 'tem', 'tÃªm', 'ter',
      // PreposiÃ§Ãµes
      'com', 'para', 'por', 'sobre',
      // Artigos
      'um', 'uma', 'uns', 'umas',
      // Pronomes
      'eu', 'vocÃª', 'ele', 'ela', 'nÃ³s', 'eles', 'elas',
      // Outras palavras comuns
      'fogo', 'seu', 'sua', 'nosso', 'nossa',
      // Palavras que podem comeÃ§ar frase mas nÃ£o sÃ£o nomes
      'essa', 'esse', 'esta', 'este', 'aqui', 'agora', 'mesma', 'mesmo', 'aquela', 'aquele',
    ];
    
    // PadrÃµes explÃ­citos de apresentaÃ§Ã£o (mais confiÃ¡veis)
    const explicitPatterns = [
      /(?:meu nome Ã©|eu sou|sou o|sou a|me chamo|chamo-me|Ã© o|Ã© a|chamo)\s+([a-zÃ¡Ã Ã¢Ã£Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ§]{3,25})/i,
      /(?:fala com|estÃ¡ falando com|falo com)\s+([a-zÃ¡Ã Ã¢Ã£Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ§]{3,25})/i,
      // PadrÃ£o para "com [Nome]" no final ou meio da frase (ex: "Essa mesma noite, com Oscar")
      /,?\s*com\s+([A-ZÃÃ€Ã‚ÃƒÃ‰ÃŠÃÃ“Ã”Ã•ÃšÃ‡][a-zÃ¡Ã Ã¢Ã£Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ§]{2,20})\.?$/i,
      // PadrÃ£o para "aqui Ã© [Nome]" ou "aqui Ã© o [Nome]"
      /aqui (?:Ã©|fala)\s+(?:o\s+|a\s+)?([a-zÃ¡Ã Ã¢Ã£Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ§]{3,25})/i,
    ];

    for (const pattern of explicitPatterns) {
      const match = text.match(pattern);
      if (match && match[1]) {
        const name = match[1].trim();
        // Validar: mÃ­nimo 3 caracteres, mÃ¡ximo 25, e nÃ£o Ã© palavra comum
        if (name.length >= 3 && name.length <= 25 && !commonWords.includes(name.toLowerCase())) {
          // Verificar se parece nome (nÃ£o Ã© nÃºmero, nÃ£o tem caracteres especiais estranhos)
          if (/^[a-zÃ¡Ã Ã¢Ã£Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ§]+$/i.test(name)) {
            // Capitalizar primeira letra
            return name.charAt(0).toUpperCase() + name.slice(1).toLowerCase();
          }
        }
      }
    }

    // Se resposta Ã© muito curta (1 palavra) e parece ser sÃ³ o nome
    const words = text.trim().split(/\s+/);
    if (words.length === 1) {
      const word = words[0];
      // Validar: mÃ­nimo 3 caracteres, mÃ¡ximo 20, nÃ£o Ã© palavra comum, parece nome
      if (word.length >= 3 && word.length <= 20 && 
          !commonWords.includes(word.toLowerCase()) &&
          /^[a-zÃ¡Ã Ã¢Ã£Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ§]+$/i.test(word)) {
        // Se comeÃ§a com maiÃºscula ou tem 4+ caracteres, provavelmente Ã© nome
        if (/^[A-ZÃÃ€Ã‚ÃƒÃ‰ÃŠÃÃ“Ã”Ã•ÃšÃ‡]/.test(word) || word.length >= 4) {
          return word.charAt(0).toUpperCase() + word.slice(1).toLowerCase();
        }
      }
    }

    // NOVA LÃ“GICA: Procurar por palavras que parecem nomes prÃ³prios na frase
    // (palavras com maiÃºscula inicial ou palavras que nÃ£o sÃ£o comuns)
    for (let i = 0; i < words.length; i++) {
      const word = words[i];
      const cleanWord = word.replace(/[.,!?;:]$/, ''); // Remove pontuaÃ§Ã£o final
      const lowerWord = cleanWord.toLowerCase();
      
      // Se a palavra comeÃ§a com maiÃºscula e tem 3+ caracteres, provavelmente Ã© nome prÃ³prio
      if (/^[A-ZÃÃ€Ã‚ÃƒÃ‰ÃŠÃÃ“Ã”Ã•ÃšÃ‡][a-zÃ¡Ã Ã¢Ã£Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ§]{2,20}$/.test(cleanWord)) {
        // Verificar se nÃ£o Ã© palavra comum
        if (!commonWords.includes(lowerWord) && /^[a-zÃ¡Ã Ã¢Ã£Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ§]+$/i.test(cleanWord)) {
          this.logger.debug(`âœ… Nome detectado por maiÃºscula inicial: ${cleanWord}`);
          return cleanWord; // JÃ¡ estÃ¡ capitalizado
        }
      }
      
      // Se a palavra tem 3+ caracteres, nÃ£o Ã© comum, e parece nome prÃ³prio
      if (cleanWord.length >= 3 && cleanWord.length <= 20 &&
          !commonWords.includes(lowerWord) &&
          /^[a-zÃ¡Ã Ã¢Ã£Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ§]+$/i.test(cleanWord)) {
        // Verificar se estÃ¡ em contexto de apresentaÃ§Ã£o (prÃ³ximo a palavras como "com", "o", "a")
        const prevWord = i > 0 ? words[i - 1].replace(/[.,!?;:]$/, '').toLowerCase() : '';
        const nextWord = i < words.length - 1 ? words[i + 1].replace(/[.,!?;:]$/, '').toLowerCase() : '';
        
        // Se estÃ¡ apÃ³s "com", "o", "a", "do", "da", "de", "seu", "sua", provavelmente Ã© nome
        if (['com', 'o', 'a', 'do', 'da', 'de', 'seu', 'sua', 'meu', 'minha'].includes(prevWord)) {
          this.logger.debug(`âœ… Nome detectado por contexto (apÃ³s "${prevWord}"): ${cleanWord}`);
          return cleanWord.charAt(0).toUpperCase() + cleanWord.slice(1).toLowerCase();
        }
        
        // Se estÃ¡ antes de pontuaÃ§Ã£o final e tem 4+ caracteres, pode ser nome
        if (word.endsWith('.') && cleanWord.length >= 4) {
          this.logger.debug(`âœ… Nome detectado no final da frase: ${cleanWord}`);
          return cleanWord.charAt(0).toUpperCase() + cleanWord.slice(1).toLowerCase();
        }
      }
    }

    return null;
  }

  /**
   * Gera contexto dinÃ¢mico
   * Usa as fases configuradas em config.conversationPhases
   */
  private generateContext(session: CallSession): string {
    const turnCount = session.conversationHistory.length;
    const duration = Date.now() - session.startedAt.getTime();
    const hasName = !!(session.prospectName && session.prospectName !== 'Visitante' && session.prospectName.length > 2);

    let context = `Turno ${turnCount + 1}. DuraÃ§Ã£o: ${Math.round(duration / 1000)}s. `;

    // Usa funÃ§Ã£o do config para determinar fase atual
    const phaseContext = generatePhaseContext(turnCount, hasName, session.prospectName || 'Cliente');
    context += phaseContext;

    return context;
  }

  /**
   * Registra mÃ©tricas do turno
   */
  private recordTurnMetrics(session: CallSession): void {
    if (!this.currentMetrics) return;

    const m = this.currentMetrics;
    
    // Usar mÃ©tricas detalhadas do STT se disponÃ­veis
    const sttTiming = m.sttTimingMetrics;
    const sttRealLatency = sttTiming?.realLatency || (m.sttEnd - m.sttStart);
    
    const latency: LatencyBreakdown = {
      // Usar latÃªncia REAL do STT (tempo atÃ© primeira parcial)
      stt: sttRealLatency,
      llm: (m.llmFirstToken || m.playbackEnd) - m.llmStart,
      tts: m.ttsFirstChunk ? m.ttsFirstChunk - m.ttsStart : 0,
      // Total = STT real + LLM + TTS (sem contar tempo de fala do usuÃ¡rio)
      total: sttRealLatency + ((m.llmFirstToken || m.playbackEnd) - m.llmStart) + (m.ttsFirstChunk ? m.ttsFirstChunk - m.ttsStart : 0),
      timeToFirstAudio: m.playbackStart ? m.playbackStart - m.sttEnd : 0,
      // Novas mÃ©tricas separadas
      speechDuration: sttTiming?.speechDuration,
      vadDelay: sttTiming?.vadWaitTime,
    };

    const turnMetrics: TurnMetrics = {
      turnId: m.turnId,
      timestamp: new Date(),
      latency,
      audioInputDuration: sttTiming?.speechDuration || 0,
      audioOutputDuration: 0,
      fillerUsed: false,
    };

    session.metrics.turns.push(turnMetrics);
    this.updateAggregateMetrics(session);

    // Log mÃ©tricas com separaÃ§Ã£o clara entre latÃªncia e tempo de fala
    this.logger.info('ğŸ“Š MÃ©tricas do turno:');
    this.logger.info(`   âš¡ LatÃªncias: STT=${latency.stt}ms | LLM=${latency.llm}ms | TTS=${latency.tts}ms`);
    if (latency.speechDuration !== undefined) {
      this.logger.info(`   ğŸ—£ï¸ Info: DuraÃ§Ã£o da fala=${latency.speechDuration}ms | VAD wait=${latency.vadDelay}ms`);
    }
    this.logger.info(`   â±ï¸ Time to First Audio: ${latency.timeToFirstAudio}ms`);
    this.logger.info(`   ğŸ“ˆ Total (latÃªncia real): ${latency.total}ms ${m.interrupted ? '(interrompido)' : ''}`);

    // AnÃ¡lise de gargalos (apenas se latÃªncia estiver alta)
    if (latency.total > 2000 || latency.timeToFirstAudio > 2000) {
      const analyzer = new LatencyAnalyzer();
      analyzer.logAnalysis(latency);
    }

    this.emit('metrics', m.turnId, latency);
  }

  /**
   * Atualiza mÃ©tricas agregadas
   */
  private updateAggregateMetrics(session: CallSession): void {
    const turns = session.metrics.turns;
    if (turns.length === 0) return;

    const sum = turns.reduce(
      (acc, t) => ({
        stt: acc.stt + t.latency.stt,
        llm: acc.llm + t.latency.llm,
        tts: acc.tts + t.latency.tts,
        total: acc.total + t.latency.total,
        timeToFirstAudio: acc.timeToFirstAudio + t.latency.timeToFirstAudio,
      }),
      { stt: 0, llm: 0, tts: 0, total: 0, timeToFirstAudio: 0 }
    );

    session.metrics.averageLatency = {
      stt: Math.round(sum.stt / turns.length),
      llm: Math.round(sum.llm / turns.length),
      tts: Math.round(sum.tts / turns.length),
      total: Math.round(sum.total / turns.length),
      timeToFirstAudio: Math.round(sum.timeToFirstAudio / turns.length),
    };
  }

  /**
   * Encerra a sessÃ£o
   */
  async endSession(callId: string): Promise<CallSummary | null> {
    const session = this.activeSessions.get(callId);
    if (!session) return null;

    session.status = 'ended';
    session.endedAt = new Date();
    session.metrics.totalDuration = session.endedAt.getTime() - session.startedAt.getTime();

    await this.config.localProvider.endCall(callId);

    const summary: CallSummary = {
      callId,
      duration: session.metrics.totalDuration,
      turns: session.conversationHistory.length,
      outcome: 'not_interested',
      metrics: session.metrics,
      transcript: session.conversationHistory,
    };

    // Parar AudioRoom (gravaÃ§Ã£o de Ã¡udio mixada)
    if (this.audioRoom) {
      await this.audioRoom.stop();
      this.audioRoom = null;
    }
    
    // Salvar transcriÃ§Ã£o da chamada
    if (this.callRecorder) {
      const recordingMetrics = {
        averageSTT: session.metrics.averageLatency.stt,
        averageLLM: session.metrics.averageLatency.llm,
        averageTTS: session.metrics.averageLatency.tts,
        averageTimeToFirstAudio: session.metrics.averageLatency.timeToFirstAudio,
      };
      const recordingPath = await this.callRecorder.stop(recordingMetrics);
      if (recordingPath) {
        this.logger.info(`ğŸ“ GravaÃ§Ã£o salva em: ${recordingPath}`);
      }
      this.callRecorder = null;
    }

    this.activeSessions.delete(callId);
    this.emit('session:ended', callId, summary);

    this.logger.info('ğŸ“Š Resumo da sessÃ£o:');
    this.logger.info(`   DuraÃ§Ã£o: ${Math.round(summary.duration / 1000)}s`);
    this.logger.info(`   Turnos: ${summary.turns}`);
    this.logger.info(`   LatÃªncia mÃ©dia: STT=${session.metrics.averageLatency.stt}ms, LLM=${session.metrics.averageLatency.llm}ms`);
    this.logger.info(`   Time to First Audio mÃ©dio: ${session.metrics.averageLatency.timeToFirstAudio}ms`);

    return summary;
  }

  /**
   * Retorna sessÃ£o ativa
   */
  getSession(callId: string): CallSession | undefined {
    return this.activeSessions.get(callId);
  }
}
