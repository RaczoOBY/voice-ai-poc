/**
 * VoiceAgent - Orquestrador principal do sistema
 * 
 * Respons√°vel por:
 * - Gerenciar o fluxo de chamadas
 * - Coordenar STT ‚Üí LLM ‚Üí TTS (com streaming)
 * - Usar fillers para reduzir lat√™ncia percebida
 * - Suporte a barge-in (interrup√ß√£o)
 * - Grava√ß√£o de chamadas
 * - Coletar m√©tricas detalhadas
 */

import { EventEmitter } from 'events';
import { createServer, IncomingMessage, ServerResponse } from 'http';
import WebSocket from 'ws';
import * as fs from 'fs';
import * as path from 'path';
import {
  VoiceAgentConfig,
  VoiceAgentEvents,
  CallSession,
  ConversationTurn,
  TurnMetrics,
  FillerContext,
  CallSummary,
  LatencyBreakdown,
  TelephonyCallEvent,
  TelnyxCallEvent,
  TwilioCallEvent,
} from '../types';
import { Logger } from '../utils/Logger';
import { config as globalConfig } from '../config';
import { VoiceIntelligence } from './VoiceIntelligence';

// Configura√ß√µes de streaming LLM ‚Üí TTS
const STREAMING_CONFIG = {
  MIN_CHARS_FOR_TTS: 60,           // M√≠nimo de caracteres antes de enviar para TTS
  SENTENCE_DELIMITERS: ['.', '!', '?', ':', ';'], // Delimitadores de frase
  MAX_BUFFER_CHARS: 200,           // M√°ximo antes de for√ßar flush
};

export class VoiceAgent extends EventEmitter {
  private config: VoiceAgentConfig;
  private activeCalls: Map<string, CallSession> = new Map();
  private logger: Logger;
  
  // Mapa de conex√µes Twilio Media Stream: callSid -> { ws, streamSid }
  private twilioStreams: Map<string, { ws: WebSocket; streamSid: string }> = new Map();
  
  // Barge-in: controle de interrup√ß√£o
  private isPlayingAudio: Map<string, boolean> = new Map();
  private bargeInDetected: Map<string, boolean> = new Map();
  
  // Grava√ß√£o de chamadas
  private callRecordings: Map<string, { userAudio: Buffer[]; agentAudio: Buffer[]; transcript: any[] }> = new Map();
  
  // Fila de TTS para serializar streams e evitar sobreposi√ß√£o de √°udio
  private ttsQueue: Map<string, Promise<void>> = new Map();
  
  // Controle de processamento para evitar turnos simult√¢neos e agregar transcri√ß√µes
  private isProcessing: Map<string, boolean> = new Map();
  private pendingTranscription: Map<string, string> = new Map();
  private transcriptionDebounceTimer: Map<string, NodeJS.Timeout> = new Map();
  private static readonly TRANSCRIPTION_DEBOUNCE_MS = 800; // Espera 800ms ap√≥s √∫ltima transcri√ß√£o antes de processar
  
  // Rastreamento de dura√ß√£o da reprodu√ß√£o (para detectar barge-in durante playback no Twilio)
  private audioPlaybackEndTime: Map<string, number> = new Map();
  private totalAudioBytesSent: Map<string, number> = new Map();
  private audioPlaybackStartTime: Map<string, number> = new Map();
  
  // Grace period para evitar falsos positivos de barge-in por eco
  private static readonly BARGE_IN_GRACE_PERIOD_MS = 1500; // Ignora barge-in por √°udio nos primeiros 1.5s
  private static readonly BARGE_IN_RMS_THRESHOLD = 1500; // Threshold mais alto para evitar ru√≠dos

  // Camada de intelig√™ncia centralizada (pensamentos, contexto, etc)
  private intelligence: VoiceIntelligence;

  constructor(config: VoiceAgentConfig) {
    super();
    this.config = config;
    this.logger = new Logger('VoiceAgent');
    
    // Inicializar camada de intelig√™ncia
    this.intelligence = new VoiceIntelligence({
      llm: config.llm,
      systemPrompt: config.systemPrompt,
      enableThinking: globalConfig.thinkingEngine?.enabled ?? false,
    });
  }

  /**
   * Envia √°udio para a chamada (detecta automaticamente Twilio ou Telnyx)
   */
  private async sendAudioToCall(callId: string, audioBuffer: Buffer): Promise<void> {
    // Verificar se √© uma chamada Twilio (tem stream registrado)
    const twilioStream = this.twilioStreams.get(callId);
    
    if (twilioStream) {
      // √â Twilio - enviar via WebSocket diretamente
      this.sendTwilioAudio(callId, audioBuffer);
    } else {
      // √â Telnyx ou outro - usar o provider
      await this.config.telephony.sendAudio(callId, audioBuffer);
    }
  }

  // Tabela de lookup para convers√£o linear ‚Üí Œº-law (mais precisa)
  private static readonly LINEAR_TO_MULAW: number[] = (() => {
    const table: number[] = new Array(65536);
    for (let i = 0; i < 65536; i++) {
      // Converter de unsigned para signed
      let sample = i < 32768 ? i : i - 65536;
      
      const BIAS = 0x84;
      const CLIP = 32635;
      const sign = (sample >> 8) & 0x80;
      
      if (sign !== 0) sample = -sample;
      if (sample > CLIP) sample = CLIP;
      
      sample = sample + BIAS;
      
      let exponent = 7;
      for (let expMask = 0x4000; (sample & expMask) === 0 && exponent > 0; exponent--, expMask >>= 1);
      
      const mantissa = (sample >> (exponent + 3)) & 0x0F;
      const mulaw = ~(sign | (exponent << 4) | mantissa);
      
      table[i] = mulaw & 0xFF;
    }
    return table;
  })();

  // Tabela de lookup para convers√£o Œº-law ‚Üí linear
  private static readonly MULAW_TO_LINEAR: number[] = (() => {
    const table: number[] = new Array(256);
    for (let i = 0; i < 256; i++) {
      const mulaw = ~i;
      const sign = mulaw & 0x80;
      const exponent = (mulaw >> 4) & 0x07;
      const mantissa = mulaw & 0x0F;
      let sample = ((mantissa << 3) + 0x84) << exponent;
      sample -= 0x84;
      table[i] = sign !== 0 ? -sample : sample;
    }
    return table;
  })();

  /**
   * Converte PCM 16-bit 16kHz para Œº-law 8kHz (formato Twilio)
   */
  private convertPcmToMulaw(pcmBuffer: Buffer): Buffer {
    const inputSamples = pcmBuffer.length / 2;
    const outputSamples = Math.floor(inputSamples / 2); // Downsample 2x
    const mulawBuffer = Buffer.alloc(outputSamples);
    
    for (let i = 0; i < outputSamples; i++) {
      // Ler sample PCM 16-bit e fazer m√©dia com o pr√≥ximo (anti-aliasing simples)
      const sample1 = pcmBuffer.readInt16LE(i * 4);
      const sample2 = pcmBuffer.readInt16LE(i * 4 + 2);
      const avgSample = Math.round((sample1 + sample2) / 2);
      
      // Converter para unsigned e usar tabela de lookup
      const unsigned = avgSample < 0 ? avgSample + 65536 : avgSample;
      mulawBuffer[i] = VoiceAgent.LINEAR_TO_MULAW[unsigned];
    }
    
    return mulawBuffer;
  }

  /**
   * Converte Œº-law 8kHz para PCM 16-bit 16kHz (para STT)
   */
  private convertMulawToPcm(mulawBuffer: Buffer): Buffer {
    // Upsample 2x (8kHz ‚Üí 16kHz) com interpola√ß√£o linear
    const pcmBuffer = Buffer.alloc(mulawBuffer.length * 4); // 2x samples, 2 bytes cada
    
    for (let i = 0; i < mulawBuffer.length; i++) {
      const sample = VoiceAgent.MULAW_TO_LINEAR[mulawBuffer[i]];
      const nextSample = i < mulawBuffer.length - 1 
        ? VoiceAgent.MULAW_TO_LINEAR[mulawBuffer[i + 1]]
        : sample;
      
      // Escrever sample original
      pcmBuffer.writeInt16LE(sample, i * 4);
      // Interpolar para o sample intermedi√°rio
      pcmBuffer.writeInt16LE(Math.round((sample + nextSample) / 2), i * 4 + 2);
    }
    
    return pcmBuffer;
  }

  /**
   * Envia √°udio para Twilio Media Stream
   * Se outputFormat='ulaw_8000', envia direto. Sen√£o, converte PCM 16kHz para mulaw 8kHz
   */
  private sendTwilioAudio(callId: string, audioBuffer: Buffer): void {
    const stream = this.twilioStreams.get(callId);
    if (!stream) {
      this.logger.warn(`Twilio stream n√£o encontrado para call ${callId}`);
      return;
    }

    const { ws, streamSid } = stream;
    if (ws.readyState !== WebSocket.OPEN) {
      this.logger.warn(`WebSocket n√£o est√° aberto para call ${callId}`);
      return;
    }

    // Verificar se j√° est√° em Œº-law (ElevenLabs outputFormat='ulaw_8000')
    const isAlreadyMulaw = globalConfig.elevenlabs?.outputFormat === 'ulaw_8000';
    const mulawBuffer = isAlreadyMulaw ? audioBuffer : this.convertPcmToMulaw(audioBuffer);
    
    // Rastrear bytes enviados para calcular tempo de reprodu√ß√£o
    // Œº-law 8kHz = 8000 bytes/segundo
    const currentBytes = this.totalAudioBytesSent.get(callId) || 0;
    const newTotalBytes = currentBytes + mulawBuffer.length;
    this.totalAudioBytesSent.set(callId, newTotalBytes);
    
    // Calcular dura√ß√£o do chunk atual em ms
    const chunkDurationMs = (mulawBuffer.length / 8000) * 1000;
    const now = Date.now();
    const currentEndTime = this.audioPlaybackEndTime.get(callId) || 0;
    
    // Se j√° tem um tempo de t√©rmino no futuro, adicionar a dura√ß√£o do novo chunk
    // Sen√£o, come√ßar do agora + dura√ß√£o do chunk
    let newEndTime: number;
    if (currentEndTime > now) {
      // √Åudio j√° est√° em reprodu√ß√£o - adicionar ao final
      newEndTime = currentEndTime + chunkDurationMs;
    } else {
      // Primeiro chunk ou √°udio anterior j√° terminou
      newEndTime = now + chunkDurationMs;
    }
    
    this.audioPlaybackEndTime.set(callId, newEndTime);
    
    // Calcular tempo total de √°udio restante para reprodu√ß√£o
    const totalRemainingMs = newEndTime - now;
    this.logger.debug(`üìä √Åudio: +${Math.round(chunkDurationMs)}ms, total restante: ${Math.round(totalRemainingMs)}ms, termina em: ${new Date(newEndTime).toISOString().substring(11, 23)}`);
    
    // Enviar √°udio em chunks de 20ms (160 samples a 8kHz = 160 bytes)
    const chunkSize = 160;
    const totalChunks = Math.ceil(mulawBuffer.length / chunkSize);
    
    for (let i = 0; i < mulawBuffer.length; i += chunkSize) {
      const chunk = mulawBuffer.subarray(i, Math.min(i + chunkSize, mulawBuffer.length));
      const base64Audio = chunk.toString('base64');
      
      const message = JSON.stringify({
        event: 'media',
        streamSid: streamSid,
        media: {
          payload: base64Audio,
        },
      });

      ws.send(message);
    }
  }

  /**
   * Inicia o servidor HTTP para webhooks
   */
  async start(port: number): Promise<void> {
    const server = createServer(this.handleWebhook.bind(this));
    
    // Criar WebSocket servers sem path (vamos rotear manualmente)
    const wssAudio = new WebSocket.Server({ noServer: true });
    this.setupAudioWebSocket(wssAudio);
    
    const wssMediaStream = new WebSocket.Server({ noServer: true });
    this.setupTwilioMediaStream(wssMediaStream);
    
    // Handler para upgrade de conex√£o WebSocket
    server.on('upgrade', (request, socket, head) => {
      const pathname = request.url || '';
      this.logger.info(`üîå WebSocket upgrade request: ${pathname}`);
      
      if (pathname === '/audio' || pathname.startsWith('/audio?')) {
        wssAudio.handleUpgrade(request, socket, head, (ws) => {
          wssAudio.emit('connection', ws, request);
        });
      } else if (pathname === '/media-stream' || pathname.startsWith('/media-stream?')) {
        wssMediaStream.handleUpgrade(request, socket, head, (ws) => {
          wssMediaStream.emit('connection', ws, request);
        });
      } else {
        this.logger.warn(`üîå WebSocket path n√£o reconhecido: ${pathname}`);
        socket.destroy();
      }
    });
    
    server.listen(port, () => {
      this.logger.info(`üéß Voice Agent listening on port ${port}`);
      this.logger.info(`üîå WebSocket Telnyx ready at ws://localhost:${port}/audio`);
      this.logger.info(`üîå WebSocket Twilio ready at ws://localhost:${port}/media-stream`);
    });

    // Configurar handlers de eventos de telefonia
    this.config.telephony.onCallEvent((event) => {
      this.handleTelephonyEvent(event);
    });
  }

  /**
   * Configura WebSocket server para Twilio Media Streams
   */
  private setupTwilioMediaStream(wss: WebSocket.Server): void {
    wss.on('connection', (ws) => {
      this.logger.info(`üîå Twilio Media Stream conectado`);

      let currentCallSid: string | null = null;
      let audioBuffer: Buffer[] = [];
      let sttReady = false; // Flag para indicar quando o STT est√° pronto

      ws.on('message', (data: Buffer) => {
        try {
          const message = JSON.parse(data.toString());
          
          switch (message.event) {
            case 'connected':
              this.logger.info('üì° Twilio Media Stream: connected');
              break;

            case 'start':
              currentCallSid = message.start?.callSid;
              const streamSid = message.start?.streamSid;
              this.logger.info(`üéôÔ∏è Twilio Media Stream: start (call=${currentCallSid}, stream=${streamSid})`);
              this.logger.info(`üìä Formato: ${JSON.stringify(message.start?.mediaFormat)}`);
              
              // Guardar refer√™ncia do WebSocket para enviar √°udio depois
              if (currentCallSid && streamSid) {
                this.twilioStreams.set(currentCallSid, { ws, streamSid });
                this.logger.info(`‚úÖ Stream registrado para call ${currentCallSid}`);
              }
              
              // Iniciar sess√£o de chamada (async IIFE para aguardar STT)
              if (currentCallSid && !this.activeCalls.has(currentCallSid)) {
                const callSid = currentCallSid; // Capturar para closure
                
                this.activeCalls.set(callSid, {
                  id: callSid,
                  phoneNumber: message.start?.customParameters?.to || 'unknown',
                  startedAt: new Date(),
                  status: 'active',
                  conversationHistory: [],
                  metrics: {
                    totalDuration: 0,
                    turns: [],
                    averageLatency: { stt: 0, llm: 0, tts: 0, total: 0, timeToFirstAudio: 0 },
                    peakLatency: { stt: 0, llm: 0, tts: 0, total: 0, timeToFirstAudio: 0 },
                    fillersUsed: 0,
                    transcriptionErrors: 0,
                  },
                });
                
                // Async: iniciar STT e sauda√ß√£o
                (async () => {
                  // Iniciar stream de transcri√ß√£o (STT) - AGUARDAR conex√£o
                  if (this.config.transcriber.startStream && this.config.transcriber.onTranscript) {
                    this.logger.info(`üé§ Iniciando STT streaming para call ${callSid}`);
                    
                    try {
                      await this.config.transcriber.startStream(callSid);
                      sttReady = true;
                      this.logger.info(`‚úÖ STT streaming pronto para call ${callSid}`);
                    } catch (error) {
                      this.logger.error(`‚ùå Falha ao iniciar STT streaming:`, error);
                    }
                    
                    // Configurar callback para transcri√ß√µes
                    this.config.transcriber.onTranscript(callSid, async (result) => {
                      const text = result.text.trim();
                      if (text) {
                        this.logger.info(`üìù Transcri√ß√£o recebida: "${text}"`);
                        await this.processTurnFromText(callSid, text);
                      }
                    });
                  }
                  
                  // Iniciar grava√ß√£o da chamada
                  this.startRecording(callSid);
                  
                  // Gerar sauda√ß√£o inicial
                  this.generateGreeting(callSid);
                })();
              }
              break;

            case 'media':
              if (message.media && currentCallSid) {
                // Decodificar √°udio de base64 (mulaw 8kHz)
                const audioChunk = Buffer.from(message.media.payload, 'base64');
                
                // Converter Œº-law 8kHz ‚Üí PCM 16kHz para o STT
                const pcmChunk = this.convertMulawToPcm(audioChunk);
                
                // Gravar √°udio do usu√°rio
                this.recordUserAudio(currentCallSid, audioChunk);
                
                // Detectar barge-in: se estamos reproduzindo √°udio e usu√°rio fala
                if (this.isPlayingAudio.get(currentCallSid)) {
                  // Verificar grace period (evita falsos positivos por eco)
                  const playbackStartTime = this.audioPlaybackStartTime.get(currentCallSid) || 0;
                  const timeSincePlaybackStart = Date.now() - playbackStartTime;
                  
                  if (timeSincePlaybackStart > VoiceAgent.BARGE_IN_GRACE_PERIOD_MS) {
                    // Verificar se h√° energia no √°udio (n√£o √© sil√™ncio) com threshold mais alto
                    const hasEnergy = this.detectAudioEnergy(pcmChunk, VoiceAgent.BARGE_IN_RMS_THRESHOLD);
                    if (hasEnergy) {
                      this.detectBargeIn(currentCallSid);
                    }
                  }
                }
                
                // Enviar para o transcriber (STT) apenas se estiver pronto
                if (sttReady && this.config.transcriber.feedAudio && currentCallSid) {
                  this.config.transcriber.feedAudio(currentCallSid, pcmChunk);
                } else if (!sttReady) {
                  // Buffer enquanto STT n√£o est√° pronto (descarta para evitar overflow)
                  // Os primeiros ~100ms de √°udio ser√£o perdidos, mas √© aceit√°vel
                }
              }
              break;

            case 'mark':
              this.logger.debug(`üè∑Ô∏è Twilio mark: ${message.mark?.name}`);
              break;

            case 'stop':
              this.logger.info(`‚èπÔ∏è Twilio Media Stream: stop`);
              if (currentCallSid) {
                this.handleCallHangup(currentCallSid);
              }
              break;
          }
        } catch (error) {
          this.logger.error('Erro ao processar Twilio Media Stream:', error);
        }
      });

      ws.on('close', () => {
        this.logger.info(`üîå Twilio Media Stream desconectado`);
        if (currentCallSid) {
          this.activeCalls.delete(currentCallSid);
        }
      });

      ws.on('error', (error) => {
        this.logger.error(`Erro WebSocket Twilio:`, error);
      });
    });
  }

  /**
   * Configura WebSocket server para receber √°udio das chamadas
   */
  private setupAudioWebSocket(wss: WebSocket.Server): void {
    wss.on('connection', (ws, req) => {
      // Extrair callId da URL: /audio/call-id
      const callId = req.url?.split('/').pop();
      if (!callId || !this.activeCalls.has(callId)) {
        this.logger.warn(`WebSocket: callId inv√°lido ou sess√£o n√£o encontrada: ${callId}`);
        ws.close();
        return;
      }

      this.logger.info(`üîå WebSocket conectado para chamada ${callId}`);

      // Buffer para acumular chunks de √°udio
      let audioBuffer: Buffer[] = [];
      let silenceTimeout: NodeJS.Timeout | null = null;
      const SILENCE_THRESHOLD_MS = 500; // 500ms de sil√™ncio = fim do turno

      ws.on('message', (data: Buffer) => {
        // Acumular √°udio
        audioBuffer.push(data);

        // Reset do timeout de sil√™ncio
        if (silenceTimeout) clearTimeout(silenceTimeout);
        
        silenceTimeout = setTimeout(async () => {
          // Sil√™ncio detectado - processar turno
          if (audioBuffer.length > 0) {
            const fullAudio = Buffer.concat(audioBuffer);
            audioBuffer = [];
            
            this.logger.debug(`üé§ √Åudio recebido: ${fullAudio.length} bytes, processando turno...`);
            
            // Processar o turno de conversa
            await this.processTurn(callId, fullAudio);
          }
        }, SILENCE_THRESHOLD_MS);
      });

      ws.on('close', () => {
        this.logger.info(`üîå WebSocket desconectado para chamada ${callId}`);
        if (silenceTimeout) clearTimeout(silenceTimeout);
      });

      ws.on('error', (error) => {
        this.logger.error(`Erro WebSocket para chamada ${callId}:`, error);
      });
    });
  }

  /**
   * Inicia uma chamada outbound
   */
  async makeCall(phoneNumber: string, prospectData?: { name?: string; company?: string }): Promise<string> {
    this.logger.info(`üìû Iniciando chamada para ${phoneNumber}`);

    const callId = await this.config.telephony.makeCall(phoneNumber);

    const session: CallSession = {
      id: callId,
      phoneNumber,
      prospectName: prospectData?.name,
      companyName: prospectData?.company,
      startedAt: new Date(),
      status: 'initiating',
      conversationHistory: [],
      metrics: {
        totalDuration: 0,
        turns: [],
        averageLatency: { stt: 0, llm: 0, tts: 0, total: 0, timeToFirstAudio: 0 },
        peakLatency: { stt: 0, llm: 0, tts: 0, total: 0, timeToFirstAudio: 0 },
        fillersUsed: 0,
        transcriptionErrors: 0,
      },
      internalThoughts: [], // Inicializar array de pensamentos internos
    };

    this.activeCalls.set(callId, session);
    this.emit('call:started', callId);

    return callId;
  }

  /**
   * Processa um turno de conversa completo
   * Este √© o core do sistema: User Audio ‚Üí STT ‚Üí LLM ‚Üí TTS ‚Üí Agent Audio
   */
  async processTurn(callId: string, userAudio: Buffer): Promise<void> {
    const session = this.activeCalls.get(callId);
    if (!session) {
      this.logger.error(`Sess√£o n√£o encontrada: ${callId}`);
      return;
    }

    const turnId = this.config.metrics.startTurn(callId);
    const timestamps: Record<string, number> = {};
    
    this.emit('turn:started', callId, turnId);
    this.logger.debug(`üîÑ Turno ${turnId} iniciado`);

    try {
      // ============================================
      // FASE 1: Speech-to-Text
      // ============================================
      timestamps.sttStart = Date.now();
      this.config.metrics.recordEvent({
        stage: 'stt_start',
        timestamp: timestamps.sttStart,
        callId,
        turnId,
      });

      const transcription = await this.config.transcriber.transcribe(userAudio);
      
      timestamps.sttEnd = Date.now();
      const sttDuration = timestamps.sttEnd - timestamps.sttStart;
      
      this.config.metrics.recordEvent({
        stage: 'stt_end',
        timestamp: timestamps.sttEnd,
        callId,
        turnId,
        metadata: { text: transcription.text, duration: sttDuration },
      });

      this.logger.info(`üìù STT (${sttDuration}ms): "${transcription.text}"`);
      this.emit('metrics:update', { stage: 'STT', duration: sttDuration });

      // Validar transcri√ß√£o
      if (!transcription.text || transcription.text.trim().length === 0) {
        this.logger.warn('Transcri√ß√£o vazia, ignorando turno');
        session.metrics.transcriptionErrors++;
        return;
      }

      // Adicionar ao hist√≥rico
      session.conversationHistory.push({
        role: 'user',
        content: transcription.text,
        timestamp: new Date(),
      });

      // ============================================
      // FASE 2: Disparar Filler (paralelo ao LLM)
      // ============================================
      const fillerContext: FillerContext = {
        prospectName: session.prospectName,
        lastUserMessage: transcription.text,
        conversationStage: this.intelligence.detectConversationStage(session),
      };

      const filler = this.config.fillerManager.getFiller(fillerContext);
      let fillerSent = false;

      if (filler) {
        // Enviar filler imediatamente enquanto LLM processa
        timestamps.fillerStart = Date.now();
        await this.sendAudioToCall(callId, filler.audioBuffer);
        fillerSent = true;
        session.metrics.fillersUsed++;
        
        this.logger.debug(`üó£Ô∏è Filler enviado: "${filler.text}"`);
        this.emit('filler:played', callId, filler.text);
      }

      // ============================================
      // FASE 3: LLM Processing
      // ============================================
      timestamps.llmStart = Date.now();
      this.config.metrics.recordEvent({
        stage: 'llm_start',
        timestamp: timestamps.llmStart,
        callId,
        turnId,
      });

      // Construir mensagens para o LLM (usa intelig√™ncia centralizada com pensamentos)
      const messages = this.intelligence.buildLLMMessages(session);
      const llmResponse = await this.config.llm.generate(messages, {
        maxTokens: 150, // Respostas concisas
        temperature: 0.7,
      });

      timestamps.llmEnd = Date.now();
      const llmDuration = timestamps.llmEnd - timestamps.llmStart;

      this.config.metrics.recordEvent({
        stage: 'llm_end',
        timestamp: timestamps.llmEnd,
        callId,
        turnId,
        metadata: { text: llmResponse.text, duration: llmDuration },
      });

      this.logger.info(`ü§ñ LLM (${llmDuration}ms): "${llmResponse.text}"`);
      this.emit('metrics:update', { stage: 'LLM', duration: llmDuration });

      // Adicionar resposta ao hist√≥rico
      session.conversationHistory.push({
        role: 'agent',
        content: llmResponse.text,
        timestamp: new Date(),
      });

      // ============================================
      // FASE 4: Text-to-Speech
      // ============================================
      timestamps.ttsStart = Date.now();
      this.config.metrics.recordEvent({
        stage: 'tts_start',
        timestamp: timestamps.ttsStart,
        callId,
        turnId,
      });

      const ttsResult = await this.config.tts.synthesize(llmResponse.text);

      timestamps.ttsFirstByte = Date.now();
      this.config.metrics.recordEvent({
        stage: 'tts_first_byte',
        timestamp: timestamps.ttsFirstByte,
        callId,
        turnId,
      });

      // Enviar √°udio para o telefone
      await this.sendAudioToCall(callId, ttsResult.audioBuffer);

      timestamps.ttsEnd = Date.now();
      const ttsDuration = timestamps.ttsEnd - timestamps.ttsStart;

      this.config.metrics.recordEvent({
        stage: 'tts_end',
        timestamp: timestamps.ttsEnd,
        callId,
        turnId,
        metadata: { duration: ttsDuration, characters: ttsResult.characterCount },
      });

      this.logger.info(`üîä TTS (${ttsDuration}ms): ${ttsResult.characterCount} chars`);
      this.emit('metrics:update', { stage: 'TTS', duration: ttsDuration });

      // ============================================
      // FASE 5: Calcular m√©tricas do turno
      // ============================================
      const latency: LatencyBreakdown = {
        stt: sttDuration,
        llm: llmDuration,
        tts: ttsDuration,
        total: timestamps.ttsEnd - timestamps.sttStart,
        timeToFirstAudio: fillerSent 
          ? (timestamps.fillerStart! - timestamps.sttStart)
          : (timestamps.ttsFirstByte - timestamps.sttStart),
      };

      const turnMetrics: TurnMetrics = {
        turnId,
        timestamp: new Date(),
        latency,
        audioInputDuration: userAudio.length / 32, // Aproxima√ß√£o baseada em 16kHz mono
        audioOutputDuration: ttsResult.duration,
        fillerUsed: fillerSent,
        fillerText: filler?.text,
      };

      session.metrics.turns.push(turnMetrics);
      this.updateAggregateMetrics(session);

      this.emit('turn:ended', callId, turnId, turnMetrics);
      
      this.logger.info(`‚úÖ Turno completo - Total: ${latency.total}ms, First Audio: ${latency.timeToFirstAudio}ms`);

    } catch (error) {
      this.logger.error(`Erro no turno ${turnId}:`, error);
      this.emit('error', error as Error, `turn:${turnId}`);
    }
  }

  /**
   * Processa um turno quando j√° temos o texto transcrito (STT streaming)
   * USA DEBOUNCE: Transcri√ß√µes consecutivas s√£o agregadas antes de processar
   * Isso evita respostas duplicadas quando STT envia m√∫ltiplos segmentos
   */
  async processTurnFromText(callId: string, userText: string): Promise<void> {
    const session = this.activeCalls.get(callId);
    if (!session) {
      this.logger.error(`Sess√£o n√£o encontrada: ${callId}`);
      return;
    }

    // Verificar se ainda tem √°udio tocando do turno anterior (barge-in por transcri√ß√£o)
    const now = Date.now();
    const playbackEndTime = this.audioPlaybackEndTime.get(callId) || 0;
    const audioStillPlaying = now < playbackEndTime;
    
    this.logger.debug(`üìä Estado de reprodu√ß√£o: playbackEndTime=${playbackEndTime}, now=${now}, diff=${playbackEndTime - now}ms`);
    
    if (audioStillPlaying && !this.bargeInDetected.get(callId)) {
      const remainingTime = playbackEndTime - now;
      this.logger.info(`üîá BARGE-IN DETECTADO por transcri√ß√£o! (${Math.round(remainingTime)}ms restantes de √°udio)`);
      this.bargeInDetected.set(callId, true);
      this.isPlayingAudio.set(callId, false);
      this.audioPlaybackEndTime.set(callId, 0);
      this.totalAudioBytesSent.set(callId, 0);
      
      // Limpar buffer de √°udio no Twilio
      this.clearTwilioAudioBuffer(callId);
      
      // Cancelar fila de TTS pendente
      this.cancelTTSQueue(callId);
    }

    // Resetar flag de barge-in se existir (nova transcri√ß√£o = usu√°rio terminou de falar)
    if (this.bargeInDetected.get(callId)) {
      this.logger.info(`üîá Barge-in pendente resetado - processando nova transcri√ß√£o`);
      this.bargeInDetected.set(callId, false);
    }

    // Agregar texto com transcri√ß√£o pendente
    const pendingText = this.pendingTranscription.get(callId) || '';
    const aggregatedText = pendingText ? `${pendingText} ${userText}` : userText;
    this.pendingTranscription.set(callId, aggregatedText);

    // Se j√° est√° processando, apenas agregar e esperar
    if (this.isProcessing.get(callId)) {
      this.logger.debug(`üìù Texto agregado (processando): "${userText}" ‚Üí "${aggregatedText.substring(0, 50)}..."`);
      return;
    }

    // Cancelar timer anterior se existir
    const existingTimer = this.transcriptionDebounceTimer.get(callId);
    if (existingTimer) {
      clearTimeout(existingTimer);
    }

    // Agendar processamento ap√≥s debounce
    const timer = setTimeout(async () => {
      const textToProcess = this.pendingTranscription.get(callId);
      if (!textToProcess) return;
      
      // Limpar buffer pendente
      this.pendingTranscription.delete(callId);
      this.transcriptionDebounceTimer.delete(callId);
      
      // Processar o texto agregado
      await this.processAggregatedText(callId, textToProcess);
    }, VoiceAgent.TRANSCRIPTION_DEBOUNCE_MS);
    
    this.transcriptionDebounceTimer.set(callId, timer);
    this.logger.debug(`‚è≥ Debounce iniciado (${VoiceAgent.TRANSCRIPTION_DEBOUNCE_MS}ms) para: "${userText}"`);
  }

  /**
   * Processa o texto agregado ap√≥s debounce
   * USA STREAMING: LLM gera texto ‚Üí chunks v√£o para TTS ‚Üí √°udio vai para Twilio
   * Suporta barge-in (interrup√ß√£o quando usu√°rio fala)
   */
  private async processAggregatedText(callId: string, userText: string): Promise<void> {
    const session = this.activeCalls.get(callId);
    if (!session) {
      this.logger.error(`Sess√£o n√£o encontrada: ${callId}`);
      return;
    }

    // Marcar que est√° processando (evita m√∫ltiplos turnos)
    this.isProcessing.set(callId, true);
    
    // Resetar contador de bytes enviados (para m√©tricas deste turno)
    // N√ÉO resetar audioPlaybackEndTime aqui - ser√° atualizado quando enviar novo √°udio
    this.totalAudioBytesSent.set(callId, 0);

    const turnId = this.config.metrics.startTurn(callId);
    const timestamps: Record<string, number> = {};
    let interrupted = false;
    
    this.emit('turn:started', callId, turnId);
    this.logger.info(`üîÑ Turno ${turnId} iniciado (texto agregado: "${userText.substring(0, 60)}${userText.length > 60 ? '...' : ''}")`);

    // Gravar transcri√ß√£o do usu√°rio
    this.recordTranscript(callId, 'user', userText);

    // Tentar extrair nome do cliente da transcri√ß√£o
    this.intelligence.tryUpdateProspectName(session, userText);

    try {
      // Adicionar ao hist√≥rico
      session.conversationHistory.push({
        role: 'user',
        content: userText,
        timestamp: new Date(),
      });

      // ============================================
      // FASE 1: Disparar Filler (paralelo ao LLM)
      // ============================================
      const fillerContext: FillerContext = {
        prospectName: session.prospectName,
        lastUserMessage: userText,
        conversationStage: this.intelligence.detectConversationStage(session),
      };

      const filler = this.config.fillerManager.getFiller(fillerContext);
      let fillerSent = false;

      if (filler) {
        timestamps.fillerStart = Date.now();
        this.isPlayingAudio.set(callId, true);
        this.audioPlaybackStartTime.set(callId, Date.now());
        await this.sendAudioToCall(callId, filler.audioBuffer);
        fillerSent = true;
        session.metrics.fillersUsed++;
        
        this.logger.debug(`üó£Ô∏è Filler enviado: "${filler.text}"`);
        this.emit('filler:played', callId, filler.text);
        
        // Gravar filler como √°udio do agente
        this.recordAgentAudio(callId, filler.audioBuffer);
      }

      // ============================================
      // FASE 2: LLM Streaming + TTS Streaming
      // ============================================
      timestamps.llmStart = Date.now();
      this.config.metrics.recordEvent({
        stage: 'llm_start',
        timestamp: timestamps.llmStart,
        callId,
        turnId,
      });

      // Construir mensagens para o LLM (usa intelig√™ncia centralizada com pensamentos)
      const messages = this.intelligence.buildLLMMessages(session);
      
      // Buffer para acumular texto at√© formar uma frase
      let textBuffer = '';
      let fullResponse = '';
      let firstAudioSent = false;
      let totalTTSBytes = 0;
      let llmFirstToken = 0;
      
      // Marcar que est√° reproduzindo √°udio (para barge-in)
      this.isPlayingAudio.set(callId, true);
      this.audioPlaybackStartTime.set(callId, Date.now());

      // Verificar se streaming est√° dispon√≠vel
      const hasLLMStream = !!this.config.llm.generateStream;
      const hasTTSStream = !!this.config.tts.synthesizeStream;
      
      if (!hasLLMStream || !hasTTSStream) {
        // Fallback para modo n√£o-streaming
        this.logger.warn('‚ö†Ô∏è Streaming n√£o dispon√≠vel, usando modo batch');
        const llmResult = await this.config.llm.generate(messages, { maxTokens: 150, temperature: 0.7 });
        fullResponse = llmResult.text;
        timestamps.llmEnd = Date.now();
        
        const ttsResult = await this.config.tts.synthesize(fullResponse);
        timestamps.ttsStart = Date.now();
        timestamps.ttsFirstByte = Date.now();
        await this.sendAudioToCall(callId, ttsResult.audioBuffer);
        timestamps.ttsEnd = Date.now();
        totalTTSBytes = ttsResult.audioBuffer.length;
        firstAudioSent = true;
        
        this.recordAgentAudio(callId, ttsResult.audioBuffer);
      } else {
        // Processar LLM com streaming
        await this.config.llm.generateStream!(messages, async (chunk: string) => {
        // Verificar barge-in
        if (this.bargeInDetected.get(callId)) {
          interrupted = true;
          return;
        }
        
        if (!llmFirstToken) {
          llmFirstToken = Date.now();
          this.logger.debug(`‚ö° LLM primeiro token: ${llmFirstToken - timestamps.llmStart}ms`);
        }
        
        textBuffer += chunk;
        fullResponse += chunk;
        
        // Verificar se temos uma frase completa para enviar ao TTS
        const shouldFlush = this.shouldFlushTextBuffer(textBuffer);
        
        if (shouldFlush && !interrupted) {
          const textToSpeak = textBuffer.trim();
          textBuffer = '';
          
          if (textToSpeak.length > 0) {
            // Enfileirar TTS para garantir serializa√ß√£o (evitar sobreposi√ß√£o de √°udio)
            if (!timestamps.ttsStart) {
              timestamps.ttsStart = Date.now();
              this.config.metrics.recordEvent({
                stage: 'tts_start',
                timestamp: timestamps.ttsStart,
                callId,
                turnId,
              });
            }
            
            // Usar fila de TTS para serializar
            this.enqueueTTS(callId, textToSpeak, (audioChunk: Buffer) => {
              // Verificar barge-in antes de enviar √°udio
              if (this.bargeInDetected.get(callId)) {
                interrupted = true;
                return;
              }
              
              if (!firstAudioSent) {
                timestamps.ttsFirstByte = Date.now();
                firstAudioSent = true;
                this.config.metrics.recordEvent({
                  stage: 'tts_first_byte',
                  timestamp: timestamps.ttsFirstByte,
                  callId,
                  turnId,
                });
                this.logger.info(`‚ö° Time to First Audio: ${timestamps.ttsFirstByte - timestamps.llmStart}ms`);
              }
              
              totalTTSBytes += audioChunk.length;
              
              // Enviar chunk para Twilio/Telnyx
              this.sendAudioToCall(callId, audioChunk);
              
              // Gravar √°udio do agente
              this.recordAgentAudio(callId, audioChunk);
            });
          }
        }
        });

        // Flush do buffer restante (tamb√©m enfileirado)
        if (textBuffer.trim().length > 0 && !interrupted) {
          this.enqueueTTS(callId, textBuffer.trim(), (audioChunk: Buffer) => {
            if (this.bargeInDetected.get(callId)) {
              interrupted = true;
              return;
            }
            
            if (!firstAudioSent) {
              timestamps.ttsFirstByte = Date.now();
              firstAudioSent = true;
            }
            
            totalTTSBytes += audioChunk.length;
            this.sendAudioToCall(callId, audioChunk);
            this.recordAgentAudio(callId, audioChunk);
          });
        }
        
        timestamps.llmEnd = Date.now();
        
        // Aguardar a fila de TTS terminar antes de calcular m√©tricas
        await this.waitForTTSQueue(callId);
      } // Fim do else (streaming dispon√≠vel)

      timestamps.ttsEnd = Date.now();
      
      const llmDuration = timestamps.llmEnd - timestamps.llmStart;
      const ttsDuration = timestamps.ttsEnd - (timestamps.ttsStart || timestamps.llmEnd);
      
      // Parar flag de reprodu√ß√£o
      this.isPlayingAudio.set(callId, false);

      this.config.metrics.recordEvent({
        stage: 'llm_end',
        timestamp: timestamps.llmEnd,
        callId,
        turnId,
        metadata: { text: fullResponse, duration: llmDuration },
      });

      this.config.metrics.recordEvent({
        stage: 'tts_end',
        timestamp: timestamps.ttsEnd,
        callId,
        turnId,
        metadata: { duration: ttsDuration, bytes: totalTTSBytes },
      });

      this.logger.info(`ü§ñ LLM (${llmDuration}ms): "${fullResponse}"`);
      this.emit('metrics:update', { stage: 'LLM', duration: llmDuration });

      // Gravar resposta do agente
      this.recordTranscript(callId, 'agent', fullResponse);

      // Adicionar resposta ao hist√≥rico
      session.conversationHistory.push({
        role: 'agent',
        content: fullResponse,
        timestamp: new Date(),
      });

      // Processar pensamentos em paralelo (n√£o bloqueia)
      // Aproveita o tempo de reprodu√ß√£o do √°udio enquanto o usu√°rio ouve
      if (this.intelligence.isThinkingEnabled() && session.conversationHistory.filter(t => t.role === 'user').length > 0) {
        this.intelligence.processThoughtsInParallel(session, fullResponse).catch(err => {
          this.logger.warn('Erro ao processar pensamentos (n√£o cr√≠tico):', err);
        });
      }

      // ============================================
      // FASE 3: Calcular m√©tricas do turno
      // ============================================
      const timeToFirstAudio = fillerSent 
        ? (timestamps.fillerStart! - timestamps.llmStart)
        : (timestamps.ttsFirstByte ? timestamps.ttsFirstByte - timestamps.llmStart : llmDuration + ttsDuration);
      
      const latency: LatencyBreakdown = {
        stt: 0, // STT j√° foi feito em streaming
        llm: llmDuration,
        tts: ttsDuration,
        total: timestamps.ttsEnd - timestamps.llmStart,
        timeToFirstAudio,
      };

      // Calcular dura√ß√£o do √°udio (estimativa baseada em bytes)
      const audioFormat = globalConfig.elevenlabs?.outputFormat || 'ulaw_8000';
      const bytesPerSecond = audioFormat === 'ulaw_8000' ? 8000 : 32000;
      const audioDuration = totalTTSBytes / bytesPerSecond;

      const turnMetrics: TurnMetrics = {
        turnId,
        timestamp: new Date(),
        latency,
        audioInputDuration: 0,
        audioOutputDuration: audioDuration,
        fillerUsed: fillerSent,
        fillerText: filler?.text,
      };

      session.metrics.turns.push(turnMetrics);
      this.updateAggregateMetrics(session);
      this.config.metrics.endTurn(callId, turnId);

      this.emit('turn:ended', callId, turnId, turnMetrics);
      
      if (interrupted) {
        this.logger.info(`üîá Turno interrompido por barge-in - TTFA: ${timeToFirstAudio}ms`);
      } else {
        this.logger.info(`‚úÖ Turno completo - TTFA: ${timeToFirstAudio}ms, Total: ${latency.total}ms`);
      }
      
      // Garantir que flag de barge-in seja resetada no final do turno
      this.bargeInDetected.set(callId, false);

    } catch (error) {
      this.isPlayingAudio.set(callId, false);
      this.bargeInDetected.set(callId, false); // Reset em caso de erro tamb√©m
      this.logger.error(`Erro no turno ${turnId}:`, error);
      this.emit('error', error as Error, `turn:${turnId}`);
    } finally {
      // Sempre liberar flag de processamento
      this.isProcessing.set(callId, false);
      
      // Verificar se h√° transcri√ß√µes pendentes para processar
      const pendingText = this.pendingTranscription.get(callId);
      if (pendingText) {
        // Verificar se ainda tem √°udio tocando no Twilio
        const now = Date.now();
        const playbackEndTime = this.audioPlaybackEndTime.get(callId) || 0;
        const audioStillPlaying = now < playbackEndTime;
        
        if (audioStillPlaying) {
          // Ainda tem √°udio tocando - esperar at√© terminar + debounce
          const waitTime = (playbackEndTime - now) + VoiceAgent.TRANSCRIPTION_DEBOUNCE_MS;
          this.logger.info(`üìù Transcri√ß√£o pendente aguardando √°udio terminar (${Math.round(waitTime)}ms): "${pendingText.substring(0, 40)}..."`);
          
          // Agendar para quando o √°udio terminar (mant√©m na pendingTranscription para barge-in detectar)
          setTimeout(() => {
            const stillPendingText = this.pendingTranscription.get(callId);
            if (stillPendingText && !this.isProcessing.get(callId)) {
              this.pendingTranscription.delete(callId);
              this.processAggregatedText(callId, stillPendingText);
            }
          }, waitTime);
        } else {
          // √Åudio j√° terminou - processar ap√≥s debounce normal
          this.logger.info(`üìù Processando transcri√ß√£o pendente: "${pendingText.substring(0, 50)}..."`);
          this.pendingTranscription.delete(callId);
          setTimeout(() => {
            this.processAggregatedText(callId, pendingText);
          }, 100);
        }
      }
    }
  }

  /**
   * Verifica se deve enviar o buffer de texto para TTS
   */
  private shouldFlushTextBuffer(text: string): boolean {
    // Se buffer muito grande, for√ßar flush
    if (text.length >= STREAMING_CONFIG.MAX_BUFFER_CHARS) {
      return true;
    }
    
    // Se tem tamanho m√≠nimo E termina com delimitador de frase
    if (text.length >= STREAMING_CONFIG.MIN_CHARS_FOR_TTS) {
      const lastChar = text.trim().slice(-1);
      if (STREAMING_CONFIG.SENTENCE_DELIMITERS.includes(lastChar)) {
        return true;
      }
    }
    
    return false;
  }

  /**
   * Enfileira um TTS stream para garantir serializa√ß√£o
   * Evita sobreposi√ß√£o de √°udio quando m√∫ltiplos TTS s√£o disparados em paralelo
   */
  private enqueueTTS(
    callId: string, 
    text: string, 
    onChunk: (chunk: Buffer) => void
  ): void {
    // Verificar barge-in ANTES de enfileirar (n√£o adiciona novos TTS ap√≥s interrup√ß√£o)
    if (this.bargeInDetected.get(callId)) {
      this.logger.debug(`üîá TTS ignorado (barge-in ativo): "${text.substring(0, 30)}..."`);
      return;
    }
    
    // Obter a Promise atual da fila (ou uma resolvida se n√£o houver)
    const currentQueue = this.ttsQueue.get(callId) || Promise.resolve();
    
    // Encadear o novo TTS na fila
    const newQueue = currentQueue.then(async () => {
      // Verificar barge-in novamente antes de iniciar (pode ter mudado)
      if (this.bargeInDetected.get(callId)) {
        return;
      }
      
      try {
        if (this.config.tts.synthesizeStream) {
          await this.config.tts.synthesizeStream(text, onChunk);
        }
      } catch (error) {
        this.logger.error(`Erro TTS enfileirado:`, error);
      }
    });
    
    // Atualizar a fila
    this.ttsQueue.set(callId, newQueue);
  }

  /**
   * Aguarda a fila de TTS terminar para uma chamada espec√≠fica
   */
  private async waitForTTSQueue(callId: string): Promise<void> {
    const queue = this.ttsQueue.get(callId);
    if (queue) {
      await queue;
      // Limpar a fila ap√≥s terminar
      this.ttsQueue.delete(callId);
    }
  }

  /**
   * Detecta barge-in (usu√°rio falando durante reprodu√ß√£o do agente)
   * Verifica tanto a flag isPlayingAudio quanto o tempo estimado de t√©rmino da reprodu√ß√£o
   */
  detectBargeIn(callId: string): void {
    const now = Date.now();
    const playbackEndTime = this.audioPlaybackEndTime.get(callId) || 0;
    const isStillPlaying = this.isPlayingAudio.get(callId) || now < playbackEndTime;
    
    if (isStillPlaying) {
      const remainingTime = playbackEndTime > 0 ? Math.max(0, playbackEndTime - now) : 0;
      this.logger.info(`üîá Barge-in detectado para call ${callId} (${remainingTime}ms restantes de √°udio)`);
      this.bargeInDetected.set(callId, true);
      this.isPlayingAudio.set(callId, false);
      this.audioPlaybackEndTime.set(callId, 0); // Resetar tempo de t√©rmino
      this.totalAudioBytesSent.set(callId, 0); // Resetar contador de bytes
      
      // Enviar comando para parar √°udio no Twilio (clear buffer)
      this.clearTwilioAudioBuffer(callId);
      
      // Cancelar fila de TTS pendente (importante para resposta r√°pida)
      this.cancelTTSQueue(callId);
    }
  }

  /**
   * Cancela a fila de TTS para uma chamada (usado em barge-in)
   */
  private cancelTTSQueue(callId: string): void {
    // Remover a fila para que os TTS pendentes n√£o sejam executados
    // Os TTS que j√° est√£o rodando v√£o verificar bargeInDetected e parar
    this.ttsQueue.delete(callId);
    this.logger.debug(`üîá Fila de TTS cancelada para call ${callId}`);
  }

  /**
   * Limpa o buffer de √°udio do Twilio (para barge-in)
   */
  private clearTwilioAudioBuffer(callId: string): void {
    const stream = this.twilioStreams.get(callId);
    if (!stream) return;
    
    const { ws, streamSid } = stream;
    if (ws.readyState !== WebSocket.OPEN) return;
    
    // Enviar comando 'clear' para limpar o buffer de √°udio
    const clearMessage = JSON.stringify({
      event: 'clear',
      streamSid: streamSid,
    });
    
    ws.send(clearMessage);
    this.logger.debug(`üîá Buffer de √°udio limpo para call ${callId}`);
  }

  /**
   * Detecta se h√° energia no √°udio (n√£o √© sil√™ncio)
   * Usa RMS (Root Mean Square) para calcular energia
   */
  private detectAudioEnergy(pcmBuffer: Buffer, threshold: number = 500): boolean {
    if (pcmBuffer.length < 4) return false;
    
    let sumSquares = 0;
    const samples = pcmBuffer.length / 2;
    
    for (let i = 0; i < pcmBuffer.length; i += 2) {
      const sample = pcmBuffer.readInt16LE(i);
      sumSquares += sample * sample;
    }
    
    const rms = Math.sqrt(sumSquares / samples);
    return rms > threshold;
  }

  /**
   * Inicia grava√ß√£o de uma chamada
   */
  private startRecording(callId: string): void {
    this.callRecordings.set(callId, {
      userAudio: [],
      agentAudio: [],
      transcript: [],
    });
    this.logger.debug(`üéôÔ∏è Grava√ß√£o iniciada para call ${callId}`);
  }

  /**
   * Grava √°udio do usu√°rio
   */
  private recordUserAudio(callId: string, audio: Buffer): void {
    const recording = this.callRecordings.get(callId);
    if (recording) {
      recording.userAudio.push(audio);
    }
  }

  /**
   * Grava √°udio do agente
   */
  private recordAgentAudio(callId: string, audio: Buffer): void {
    const recording = this.callRecordings.get(callId);
    if (recording) {
      recording.agentAudio.push(audio);
    }
  }

  /**
   * Grava transcri√ß√£o
   */
  private recordTranscript(callId: string, role: 'user' | 'agent', text: string): void {
    const recording = this.callRecordings.get(callId);
    if (recording) {
      recording.transcript.push({
        role,
        text,
        timestamp: new Date().toISOString(),
      });
    }
  }

  /**
   * Salva grava√ß√£o em disco
   */
  private async saveRecording(callId: string): Promise<void> {
    const recording = this.callRecordings.get(callId);
    if (!recording) return;
    
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const dir = path.join(process.cwd(), 'recordings', `${timestamp}_twilio-${callId.substring(0, 8)}`);
    
    try {
      // Criar diret√≥rio
      fs.mkdirSync(dir, { recursive: true });
      
      // Salvar transcri√ß√£o
      fs.writeFileSync(
        path.join(dir, 'transcript.json'),
        JSON.stringify(recording.transcript, null, 2)
      );
      
      // Salvar √°udio do agente (concatenado)
      if (recording.agentAudio.length > 0) {
        const agentBuffer = Buffer.concat(recording.agentAudio);
        fs.writeFileSync(path.join(dir, 'agent_audio.raw'), agentBuffer);
      }
      
      // Salvar √°udio do usu√°rio (concatenado)
      if (recording.userAudio.length > 0) {
        const userBuffer = Buffer.concat(recording.userAudio);
        fs.writeFileSync(path.join(dir, 'user_audio.raw'), userBuffer);
      }
      
      this.logger.info(`üìÅ Grava√ß√£o salva em ${dir}`);
    } catch (error) {
      this.logger.error(`Erro ao salvar grava√ß√£o:`, error);
    }
    
    // Limpar mem√≥ria
    this.callRecordings.delete(callId);
  }

  // NOTA: buildLLMMessages, generateContext e detectConversationStage foram movidos
  // para VoiceIntelligence para centralizar a l√≥gica de intelig√™ncia do agente

  /**
   * Atualiza m√©tricas agregadas da sess√£o
   */
  private updateAggregateMetrics(session: CallSession): void {
    const turns = session.metrics.turns;
    if (turns.length === 0) return;

    // Calcular m√©dias
    const sum = turns.reduce(
      (acc, t) => ({
        stt: acc.stt + t.latency.stt,
        llm: acc.llm + t.latency.llm,
        tts: acc.tts + t.latency.tts,
        total: acc.total + t.latency.total,
        timeToFirstAudio: acc.timeToFirstAudio + t.latency.timeToFirstAudio,
      }),
      { stt: 0, llm: 0, tts: 0, total: 0, timeToFirstAudio: 0 }
    );

    session.metrics.averageLatency = {
      stt: Math.round(sum.stt / turns.length),
      llm: Math.round(sum.llm / turns.length),
      tts: Math.round(sum.tts / turns.length),
      total: Math.round(sum.total / turns.length),
      timeToFirstAudio: Math.round(sum.timeToFirstAudio / turns.length),
    };

    // Calcular picos
    session.metrics.peakLatency = turns.reduce(
      (peak, t) => ({
        stt: Math.max(peak.stt, t.latency.stt),
        llm: Math.max(peak.llm, t.latency.llm),
        tts: Math.max(peak.tts, t.latency.tts),
        total: Math.max(peak.total, t.latency.total),
        timeToFirstAudio: Math.max(peak.timeToFirstAudio, t.latency.timeToFirstAudio),
      }),
      { stt: 0, llm: 0, tts: 0, total: 0, timeToFirstAudio: 0 }
    );
  }

  /**
   * Encerra uma chamada
   */
  async endCall(callId: string, outcome: CallSummary['outcome'] = 'not_interested'): Promise<CallSummary> {
    const session = this.activeCalls.get(callId);
    if (!session) {
      throw new Error(`Sess√£o n√£o encontrada: ${callId}`);
    }

    session.status = 'ended';
    session.endedAt = new Date();
    session.metrics.totalDuration = session.endedAt.getTime() - session.startedAt.getTime();

    await this.config.telephony.endCall(callId);

    const summary: CallSummary = {
      callId,
      duration: session.metrics.totalDuration,
      turns: session.conversationHistory.length,
      outcome,
      metrics: session.metrics,
      transcript: session.conversationHistory,
    };

    // Exportar m√©tricas
    await this.config.metrics.exportMetrics(callId);

    this.activeCalls.delete(callId);
    this.emit('call:ended', callId, summary);

    this.logger.info(`üìä Chamada encerrada - Dura√ß√£o: ${Math.round(summary.duration / 1000)}s, Turnos: ${summary.turns}`);
    this.logger.info(`üìà Lat√™ncia m√©dia: STT=${session.metrics.averageLatency.stt}ms, LLM=${session.metrics.averageLatency.llm}ms, TTS=${session.metrics.averageLatency.tts}ms`);
    this.logger.info(`üìà Time to First Audio m√©dio: ${session.metrics.averageLatency.timeToFirstAudio}ms`);

    return summary;
  }

  /**
   * Handler para webhooks (suporta Telnyx JSON e Twilio form-urlencoded)
   */
  private handleWebhook(req: IncomingMessage, res: ServerResponse): void {
    const url = req.url || '/';
    
    if (req.method !== 'POST') {
      res.writeHead(405);
      res.end();
      return;
    }

    let body = '';
    req.on('data', (chunk) => (body += chunk));
    req.on('end', () => {
      try {
        const contentType = req.headers['content-type'] || '';
        
        // Twilio envia form-urlencoded, Telnyx envia JSON
        if (contentType.includes('application/x-www-form-urlencoded')) {
          // Parse Twilio webhook (form-urlencoded)
          const params = new URLSearchParams(body);
          const twilioData: Record<string, string> = {};
          params.forEach((value, key) => {
            twilioData[key] = value;
          });
          
          this.logger.debug(`üì° Twilio webhook recebido: ${url}`);
          this.logger.debug(`   Dados: ${JSON.stringify(twilioData)}`);
          
          // Rotear para o handler correto baseado na URL
          if (url.includes('/call-status')) {
            this.handleTwilioStatusWebhook(twilioData);
          } else if (url.includes('/amd-status')) {
            this.handleTwilioAmdWebhook(twilioData);
          } else {
            // Webhook gen√©rico - tentar processar como evento
            this.handleTwilioStatusWebhook(twilioData);
          }
        } else {
          // Parse Telnyx webhook (JSON)
          const event = JSON.parse(body);
          this.handleTelephonyEvent(event);
        }
        
        res.writeHead(200);
        res.end();
      } catch (error) {
        this.logger.error('Erro ao processar webhook:', error);
        res.writeHead(500);
        res.end();
      }
    });
  }

  /**
   * Handler para webhooks de status da Twilio
   */
  private handleTwilioStatusWebhook(data: Record<string, string>): void {
    const callStatus = data.CallStatus;
    const callSid = data.CallSid;
    
    this.logger.info(`üì° Twilio Status: ${callStatus} (${callSid})`);
    
    // Mapear status para evento
    const statusMap: Record<string, string> = {
      'queued': 'initiated',
      'initiated': 'initiated',
      'ringing': 'ringing',
      'in-progress': 'answered',
      'completed': 'completed',
      'busy': 'busy',
      'no-answer': 'no-answer',
      'canceled': 'canceled',
      'failed': 'failed',
    };

    const eventType = statusMap[callStatus] || callStatus;
    
    // Criar evento no formato esperado
    const event: TwilioCallEvent = {
      type: eventType as TwilioCallEvent['type'],
      payload: {
        callSid: callSid,
        accountSid: data.AccountSid,
        from: data.From,
        to: data.To,
        callStatus: callStatus,
        direction: (data.Direction || 'outbound-api') as 'outbound-api' | 'inbound',
      },
    };

    this.handleTelephonyEvent(event);
  }

  /**
   * Handler para webhooks de AMD (Answering Machine Detection) da Twilio
   */
  private handleTwilioAmdWebhook(data: Record<string, string>): void {
    const callSid = data.CallSid;
    const answeredBy = data.AnsweredBy;
    
    this.logger.info(`ü§ñ Twilio AMD: ${answeredBy} (${callSid})`);
    
    if (answeredBy?.includes('machine')) {
      this.logger.info(`üì† Caixa postal detectada`);
    } else if (answeredBy === 'human') {
      this.logger.info(`üë§ Humano detectado`);
    }
  }

  /**
   * Handler para eventos de telefonia (suporta Telnyx e Twilio)
   */
  private handleTelephonyEvent(event: TelephonyCallEvent): void {
    const eventType = event.type;
    
    // Determinar callId baseado no tipo de evento
    const callId = this.isTelnyxEvent(event) 
      ? event.payload.call_control_id 
      : event.payload.callSid;
    
    this.logger.debug(`üì° Evento Telefonia: ${eventType} para chamada ${callId}`);
    
    // Mapear eventos para a√ß√µes comuns
    if (this.isCallInitiated(eventType)) {
      this.logger.info(`üìû Chamada iniciada: ${callId}`);
    } else if (this.isCallAnswered(eventType)) {
      this.handleCallAnswered(callId);
    } else if (this.isCallEnded(eventType)) {
      this.handleCallHangup(callId);
    } else if (eventType === 'call.machine.detection.ended') {
      this.logger.info(`ü§ñ AMD: chamada ${callId}`);
    } else {
      this.logger.debug(`Evento n√£o tratado: ${eventType}`);
    }
  }

  /**
   * Type guard para verificar se √© evento Telnyx
   */
  private isTelnyxEvent(event: TelephonyCallEvent): event is TelnyxCallEvent {
    return 'call_control_id' in event.payload;
  }

  /**
   * Verifica se o evento indica chamada iniciada
   */
  private isCallInitiated(eventType: string): boolean {
    return eventType === 'call.initiated' || eventType === 'initiated';
  }

  /**
   * Verifica se o evento indica chamada atendida
   */
  private isCallAnswered(eventType: string): boolean {
    return eventType === 'call.answered' || eventType === 'answered';
  }

  /**
   * Verifica se o evento indica chamada encerrada
   */
  private isCallEnded(eventType: string): boolean {
    return eventType === 'call.hangup' || eventType === 'completed' || 
           eventType === 'busy' || eventType === 'no-answer' || 
           eventType === 'canceled' || eventType === 'failed';
  }

  /**
   * Trata quando a chamada √© atendida
   */
  private async handleCallAnswered(callId: string): Promise<void> {
    const session = this.activeCalls.get(callId);
    if (!session) {
      this.logger.warn(`Sess√£o n√£o encontrada para chamada atendida: ${callId}`);
      return;
    }

    session.status = 'connected';
    this.logger.info(`‚úÖ Chamada ${callId} atendida`);

    // Configurar callback para receber √°udio desta chamada
    this.config.telephony.onAudioReceived(callId, async (audio: Buffer) => {
      await this.processTurn(callId, audio);
    });

    // Pr√©-carregar fillers personalizados se temos o nome
    if (session.prospectName) {
      await this.config.fillerManager.preloadFillersForName?.(session.prospectName);
    }

    // Gerar sauda√ß√£o inicial
    await this.generateGreeting(callId);
  }

  /**
   * Gera a sauda√ß√£o inicial da chamada
   */
  private async generateGreeting(callId: string): Promise<void> {
    const session = this.activeCalls.get(callId);
    if (!session) return;

    this.logger.info(`üé§ Gerando sauda√ß√£o inicial para ${callId}`);

    try {
      // Gerar mensagem de abertura com o LLM (usa intelig√™ncia centralizada)
      const messages = this.intelligence.buildLLMMessages(session);
      const response = await this.config.llm.generate(messages, {
        maxTokens: 100,
        temperature: 0.7,
      });

      // Adicionar ao hist√≥rico
      session.conversationHistory.push({
        role: 'agent',
        content: response.text,
        timestamp: new Date(),
      });

      // Sintetizar e enviar √°udio
      const ttsResult = await this.config.tts.synthesize(response.text);
      
      // Resetar contadores para a sauda√ß√£o
      this.totalAudioBytesSent.set(callId, 0);
      this.audioPlaybackEndTime.set(callId, 0);
      this.isPlayingAudio.set(callId, true);
      this.audioPlaybackStartTime.set(callId, Date.now());
      
      await this.sendAudioToCall(callId, ttsResult.audioBuffer);

      this.logger.info(`‚úÖ Sauda√ß√£o enviada: "${response.text.substring(0, 50)}..."`);
    } catch (error) {
      this.logger.error(`Erro ao gerar sauda√ß√£o para ${callId}:`, error);
    }
  }

  /**
   * Trata quando a chamada √© encerrada
   */
  private async handleCallHangup(callId: string): Promise<void> {
    const session = this.activeCalls.get(callId);
    if (!session) {
      this.logger.warn(`Sess√£o n√£o encontrada para hangup: ${callId}`);
      return;
    }

    this.logger.info(`üì¥ Chamada ${callId} encerrada pelo outro lado`);
    
    // Salvar grava√ß√£o da chamada
    await this.saveRecording(callId);
    
    // Limpar todas as flags e timers
    this.isPlayingAudio.delete(callId);
    this.bargeInDetected.delete(callId);
    this.isProcessing.delete(callId);
    this.pendingTranscription.delete(callId);
    this.ttsQueue.delete(callId);
    this.audioPlaybackEndTime.delete(callId);
    this.totalAudioBytesSent.delete(callId);
    this.audioPlaybackStartTime.delete(callId);
    
    // Cancelar timer de debounce se existir
    const debounceTimer = this.transcriptionDebounceTimer.get(callId);
    if (debounceTimer) {
      clearTimeout(debounceTimer);
      this.transcriptionDebounceTimer.delete(callId);
    }
    
    // Finalizar a sess√£o
    try {
      await this.endCall(callId, 'not_interested');
    } catch (error) {
      this.logger.error(`Erro ao finalizar chamada ${callId}:`, error);
      // Limpar mesmo assim
      this.activeCalls.delete(callId);
    }
  }

  /**
   * Retorna estat√≠sticas das chamadas ativas
   */
  getActiveCallsStats(): { count: number; calls: Array<{ id: string; duration: number; turns: number }> } {
    const calls = Array.from(this.activeCalls.values()).map((session) => ({
      id: session.id,
      duration: Date.now() - session.startedAt.getTime(),
      turns: session.conversationHistory.length,
    }));

    return {
      count: calls.length,
      calls,
    };
  }
}
